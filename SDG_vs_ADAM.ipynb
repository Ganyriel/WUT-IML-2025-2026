{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df39a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GENERATING MANIFEST.CSV\n",
      "======================================================================\n",
      "\n",
      " Base path: data_recordings\n",
      "\n",
      " Processing ACCEPTED...\n",
      "p001: 242 files\n",
      "p226: 276 files\n",
      "p227: 303 files\n",
      "p228: 274 files\n",
      "p230: 287 files\n",
      "p233: 296 files\n",
      "\n",
      "Processing REJECTED...\n",
      "  p231: 107 files\n",
      "  p232: 96 files\n",
      "  p236: 102 files\n",
      "  p239: 99 files\n",
      "  p243: 82 files\n",
      "  p244: 97 files\n",
      "  p250: 103 files\n",
      "  p254: 90 files\n",
      "  p256: 86 files\n",
      "  p257: 103 files\n",
      "  p258: 92 files\n",
      "  p259: 91 files\n",
      "  p267: 98 files\n",
      "  p268: 92 files\n",
      "  p269: 90 files\n",
      "  p270: 86 files\n",
      "  p273: 94 files\n",
      "  p274: 91 files\n",
      "  p276: 88 files\n",
      "  p277: 89 files\n",
      "\n",
      "======================================================================\n",
      "MANIFEST GENERATED SUCCESFULLY\n",
      "======================================================================\n",
      "\n",
      "Archive: data_recordings\\manifest.csv\n",
      "Total archives: 3554\n",
      "  • Accepted (label=1): 1678\n",
      "  • Rejected (label=0): 1876\n",
      "\n",
      "First 5 rows:\n",
      "  speaker_id                        path  label\n",
      "0       p001  accepted\\p001\\p001_001.wav      1\n",
      "1       p001  accepted\\p001\\p001_002.wav      1\n",
      "2       p001  accepted\\p001\\p001_003.wav      1\n",
      "3       p001  accepted\\p001\\p001_004.wav      1\n",
      "4       p001  accepted\\p001\\p001_005.wav      1\n",
      "\n",
      "Columns: ['speaker_id', 'path', 'label']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING MANIFEST.CSV\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Data path\n",
    "base_path = r'data_recordings'\n",
    "\n",
    "print(f\"\\n Base path: {base_path}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "print(\"\\n Processing ACCEPTED...\")\n",
    "accepted_folder = os.path.join(base_path, 'accepted')\n",
    "if os.path.exists(accepted_folder):\n",
    "    for speaker_folder in os.listdir(accepted_folder):\n",
    "        speaker_path = os.path.join(accepted_folder, speaker_folder)\n",
    "        if os.path.isdir(speaker_path):\n",
    "            file_count = 0\n",
    "            for file in os.listdir(speaker_path):\n",
    "                if file.endswith(('.wav', '.mp3', '.flac')):\n",
    "                    relative_path = os.path.join('accepted', speaker_folder, file)\n",
    "                    rows.append({\n",
    "                        'speaker_id': speaker_folder,\n",
    "                        'path': relative_path,\n",
    "                        'label': 1  # 1 = ACCEPTED\n",
    "                    })\n",
    "                    file_count += 1\n",
    "            print(f\"{speaker_folder}: {file_count} files\")\n",
    "else:\n",
    "    print(f\"Not found: {accepted_folder}\")\n",
    "\n",
    "print(\"\\nProcessing REJECTED...\")\n",
    "rejected_folder = os.path.join(base_path, 'rejected')\n",
    "if os.path.exists(rejected_folder):\n",
    "    for speaker_folder in os.listdir(rejected_folder):\n",
    "        speaker_path = os.path.join(rejected_folder, speaker_folder)\n",
    "        if os.path.isdir(speaker_path):\n",
    "            file_count = 0\n",
    "            for file in os.listdir(speaker_path):\n",
    "                if file.endswith(('.wav', '.mp3', '.flac')):\n",
    "                    relative_path = os.path.join('rejected', speaker_folder, file)\n",
    "                    rows.append({\n",
    "                        'speaker_id': speaker_folder,\n",
    "                        'path': relative_path,\n",
    "                        'label': 0  # 0 = REJECTED\n",
    "                    })\n",
    "                    file_count += 1\n",
    "            print(f\"  {speaker_folder}: {file_count} files\")\n",
    "else:\n",
    "    print(f\" Not found: {rejected_folder}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "manifest_file = os.path.join(base_path, 'manifest.csv')\n",
    "df.to_csv(manifest_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MANIFEST GENERATED SUCCESFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nArchive: {manifest_file}\")\n",
    "print(f\"Total archives: {len(df)}\")\n",
    "print(f\"  • Accepted (label=1): {sum(df['label'] == 1)}\")\n",
    "print(f\"  • Rejected (label=0): {sum(df['label'] == 0)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7b41d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SPEAKER VERIFICATION - CNN WITH MEL-SPECTROGRAMS\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  Base path: data_recordings\n",
      "  Manifest: data_recordings\\manifest.csv\n",
      "  Max samples: All\n",
      "  Split ratios (train/val/test): 0.7/0.15/0.15\n",
      "\n",
      "======================================================================\n",
      "VERIFYING FILES AND PATHS\n",
      "======================================================================\n",
      "Base folder found\n",
      "Manifest found\n",
      "\n",
      "======================================================================\n",
      "STEP 1: LOADING DATA FROM MANIFEST.CSV\n",
      "======================================================================\n",
      "\n",
      "Total entries: 3554\n",
      "\n",
      "First 5 rows:\n",
      "  speaker_id                        path  label\n",
      "0       p001  accepted\\p001\\p001_001.wav      1\n",
      "1       p001  accepted\\p001\\p001_002.wav      1\n",
      "2       p001  accepted\\p001\\p001_003.wav      1\n",
      "3       p001  accepted\\p001\\p001_004.wav      1\n",
      "4       p001  accepted\\p001\\p001_005.wav      1\n",
      "\n",
      "Class distribution:\n",
      "  Accepted: 1678\n",
      "  Rejected: 1876\n",
      "\n",
      "Number of unique speakers: 26\n",
      "Sample speakers: ['p001' 'p226' 'p227' 'p228' 'p230' 'p233' 'p231' 'p232' 'p236' 'p239']\n",
      "\n",
      "======================================================================\n",
      "STEP 2: LOADING AUDIO FILES\n",
      "======================================================================\n",
      "  Processed 50/3554 files...\n",
      "  Processed 100/3554 files...\n",
      "  Processed 150/3554 files...\n",
      "  Processed 200/3554 files...\n",
      "  Processed 250/3554 files...\n",
      "  Processed 300/3554 files...\n",
      "  Processed 350/3554 files...\n",
      "  Processed 400/3554 files...\n",
      "  Processed 450/3554 files...\n",
      "  Processed 500/3554 files...\n",
      "  Processed 550/3554 files...\n",
      "  Processed 600/3554 files...\n",
      "  Processed 650/3554 files...\n",
      "  Processed 700/3554 files...\n",
      "  Processed 750/3554 files...\n",
      "  Processed 800/3554 files...\n",
      "  Processed 850/3554 files...\n",
      "  Processed 900/3554 files...\n",
      "  Processed 950/3554 files...\n",
      "  Processed 1000/3554 files...\n",
      "  Processed 1050/3554 files...\n",
      "  Processed 1100/3554 files...\n",
      "  Processed 1150/3554 files...\n",
      "  Processed 1200/3554 files...\n",
      "  Processed 1250/3554 files...\n",
      "  Processed 1300/3554 files...\n",
      "  Processed 1350/3554 files...\n",
      "  Processed 1400/3554 files...\n",
      "  Processed 1450/3554 files...\n",
      "  Processed 1500/3554 files...\n",
      "  Processed 1550/3554 files...\n",
      "  Processed 1600/3554 files...\n",
      "  Processed 1650/3554 files...\n",
      "  Processed 1700/3554 files...\n",
      "  Processed 1750/3554 files...\n",
      "  Processed 1800/3554 files...\n",
      "  Processed 1850/3554 files...\n",
      "  Processed 1900/3554 files...\n",
      "  Processed 1950/3554 files...\n",
      "  Processed 2000/3554 files...\n",
      "  Processed 2050/3554 files...\n",
      "  Processed 2100/3554 files...\n",
      "  Processed 2150/3554 files...\n",
      "  Processed 2200/3554 files...\n",
      "  Processed 2250/3554 files...\n",
      "  Processed 2300/3554 files...\n",
      "  Processed 2350/3554 files...\n",
      "  Processed 2400/3554 files...\n",
      "  Processed 2450/3554 files...\n",
      "  Processed 2500/3554 files...\n",
      "  Processed 2550/3554 files...\n",
      "  Processed 2600/3554 files...\n",
      "  Processed 2650/3554 files...\n",
      "  Processed 2700/3554 files...\n",
      "  Processed 2750/3554 files...\n",
      "  Processed 2800/3554 files...\n",
      "  Processed 2850/3554 files...\n",
      "  Processed 2900/3554 files...\n",
      "  Processed 2950/3554 files...\n",
      "  Processed 3000/3554 files...\n",
      "  Processed 3050/3554 files...\n",
      "  Processed 3100/3554 files...\n",
      "  Processed 3150/3554 files...\n",
      "  Processed 3200/3554 files...\n",
      "  Processed 3250/3554 files...\n",
      "  Processed 3300/3554 files...\n",
      "  Processed 3350/3554 files...\n",
      "  Processed 3400/3554 files...\n",
      "  Processed 3450/3554 files...\n",
      "  Processed 3500/3554 files...\n",
      "  Processed 3550/3554 files...\n",
      "\n",
      "Loading completed: 3554 files\n",
      "\n",
      "======================================================================\n",
      "STEP 3: GENERATING MEL-SPECTROGRAMS\n",
      "======================================================================\n",
      "  Processed 50/3554 spectrograms...\n",
      "  Processed 100/3554 spectrograms...\n",
      "  Processed 150/3554 spectrograms...\n",
      "  Processed 200/3554 spectrograms...\n",
      "  Processed 250/3554 spectrograms...\n",
      "  Processed 300/3554 spectrograms...\n",
      "  Processed 350/3554 spectrograms...\n",
      "  Processed 400/3554 spectrograms...\n",
      "  Processed 450/3554 spectrograms...\n",
      "  Processed 500/3554 spectrograms...\n",
      "  Processed 550/3554 spectrograms...\n",
      "  Processed 600/3554 spectrograms...\n",
      "  Processed 650/3554 spectrograms...\n",
      "  Processed 700/3554 spectrograms...\n",
      "  Processed 750/3554 spectrograms...\n",
      "  Processed 800/3554 spectrograms...\n",
      "  Processed 850/3554 spectrograms...\n",
      "  Processed 900/3554 spectrograms...\n",
      "  Processed 950/3554 spectrograms...\n",
      "  Processed 1000/3554 spectrograms...\n",
      "  Processed 1050/3554 spectrograms...\n",
      "  Processed 1100/3554 spectrograms...\n",
      "  Processed 1150/3554 spectrograms...\n",
      "  Processed 1200/3554 spectrograms...\n",
      "  Processed 1250/3554 spectrograms...\n",
      "  Processed 1300/3554 spectrograms...\n",
      "  Processed 1350/3554 spectrograms...\n",
      "  Processed 1400/3554 spectrograms...\n",
      "  Processed 1450/3554 spectrograms...\n",
      "  Processed 1500/3554 spectrograms...\n",
      "  Processed 1550/3554 spectrograms...\n",
      "  Processed 1600/3554 spectrograms...\n",
      "  Processed 1650/3554 spectrograms...\n",
      "  Processed 1700/3554 spectrograms...\n",
      "  Processed 1750/3554 spectrograms...\n",
      "  Processed 1800/3554 spectrograms...\n",
      "  Processed 1850/3554 spectrograms...\n",
      "  Processed 1900/3554 spectrograms...\n",
      "  Processed 1950/3554 spectrograms...\n",
      "  Processed 2000/3554 spectrograms...\n",
      "  Processed 2050/3554 spectrograms...\n",
      "  Processed 2100/3554 spectrograms...\n",
      "  Processed 2150/3554 spectrograms...\n",
      "  Processed 2200/3554 spectrograms...\n",
      "  Processed 2250/3554 spectrograms...\n",
      "  Processed 2300/3554 spectrograms...\n",
      "  Processed 2350/3554 spectrograms...\n",
      "  Processed 2400/3554 spectrograms...\n",
      "  Processed 2450/3554 spectrograms...\n",
      "  Processed 2500/3554 spectrograms...\n",
      "  Processed 2550/3554 spectrograms...\n",
      "  Processed 2600/3554 spectrograms...\n",
      "  Processed 2650/3554 spectrograms...\n",
      "  Processed 2700/3554 spectrograms...\n",
      "  Processed 2750/3554 spectrograms...\n",
      "  Processed 2800/3554 spectrograms...\n",
      "  Processed 2850/3554 spectrograms...\n",
      "  Processed 2900/3554 spectrograms...\n",
      "  Processed 2950/3554 spectrograms...\n",
      "  Processed 3000/3554 spectrograms...\n",
      "  Processed 3050/3554 spectrograms...\n",
      "  Processed 3100/3554 spectrograms...\n",
      "  Processed 3150/3554 spectrograms...\n",
      "  Processed 3200/3554 spectrograms...\n",
      "  Processed 3250/3554 spectrograms...\n",
      "  Processed 3300/3554 spectrograms...\n",
      "  Processed 3350/3554 spectrograms...\n",
      "  Processed 3400/3554 spectrograms...\n",
      "  Processed 3450/3554 spectrograms...\n",
      "  Processed 3500/3554 spectrograms...\n",
      "  Processed 3550/3554 spectrograms...\n",
      "\n",
      "Spectrograms shape: (3554, 128, 130, 1)\n",
      "\n",
      "Final split sizes:\n",
      "  Train:      2317\n",
      "  Validation: 496\n",
      "  Test:       741\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split   # kept, though no longer used\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SPEAKER VERIFICATION - CNN WITH MEL-SPECTROGRAMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# Initialization of paths\n",
    "base_path = r'data_recordings'\n",
    "manifest_path = os.path.join(base_path, 'manifest.csv')\n",
    "\n",
    "\n",
    "MAX_SAMPLES = None # TODO what's this?\n",
    "\n",
    "# Activating dropout\n",
    "dropout = False\n",
    "dropout_low = False\n",
    "\n",
    "# ### Ratios for 3-way split\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "RANDOM_STATE = 42 # TODO what's this?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Base path: {base_path}\")\n",
    "print(f\"  Manifest: {manifest_path}\")\n",
    "print(f\"  Max samples: {MAX_SAMPLES if MAX_SAMPLES else 'All'}\")\n",
    "print(f\"  Split ratios (train/val/test): {TRAIN_RATIO}/{VAL_RATIO}/{TEST_RATIO}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VERIFYING FILES AND PATHS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Checking base folder and manifest\n",
    "if not os.path.exists(base_path):\n",
    "    raise FileNotFoundError(f\"Base folder not found: {base_path}\")\n",
    "print(\"Base folder found\")\n",
    "\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(\"\\nPlease run first: python run_pipeline_to_get_data.py\")\n",
    "    raise FileNotFoundError(\"manifest.csv not found\")\n",
    "print(\"Manifest found\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 1: LOADING DATA FROM MANIFEST.CSV\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df = pd.read_csv(manifest_path)\n",
    "print(f\"\\nTotal entries: {len(df)}\")\n",
    "\n",
    "if MAX_SAMPLES:\n",
    "    df = df.head(MAX_SAMPLES)\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "if 'path' not in df.columns or 'label' not in df.columns:\n",
    "    raise ValueError(\"Incorrect manifest format\")\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Accepted: {sum(df['label'] == 1)}\")\n",
    "print(f\"  Rejected: {sum(df['label'] == 0)}\")\n",
    "\n",
    "# ### Extract speaker ID from the path\n",
    "# Assumes something like: accepted/p001/file.wav  -> speaker 'p001'\n",
    "df['speaker'] = df['path'].apply(lambda p: os.path.basename(os.path.dirname(p)))\n",
    "\n",
    "print(\"\\nNumber of unique speakers:\", df['speaker'].nunique())\n",
    "print(\"Sample speakers:\", df['speaker'].unique()[:10])\n",
    "\n",
    "def load_audio_file(file_path, base_folder, sr=22050, max_duration=3):\n",
    "    full_path = os.path.join(base_folder, file_path)\n",
    "    try:\n",
    "        y, _ = librosa.load(full_path, sr=sr, duration=max_duration)\n",
    "        y = y / (np.max(np.abs(y)) + 1e-6)\n",
    "        y, _ = librosa.effects.trim(y, top_db=20)\n",
    "        \n",
    "        target_length = sr * max_duration\n",
    "        if len(y) < target_length:\n",
    "            y = np.pad(y, (0, target_length - len(y)))\n",
    "        else:\n",
    "            y = y[:target_length]\n",
    "        return y\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: LOADING AUDIO FILES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "audio_data = []\n",
    "labels = []\n",
    "speakers = []   # keep track of speaker for each loaded sample\n",
    "failed = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    audio = load_audio_file(row['path'], base_path)\n",
    "    if audio is not None:\n",
    "        audio_data.append(audio)\n",
    "        labels.append(row['label'])\n",
    "        speakers.append(row['speaker'])\n",
    "    else:\n",
    "        failed += 1\n",
    "    \n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(df)} files...\")\n",
    "\n",
    "print(f\"\\nLoading completed: {len(audio_data)} files\")\n",
    "if failed > 0:\n",
    "    print(f\"Failed: {failed}\")\n",
    "\n",
    "if len(audio_data) == 0:\n",
    "    raise ValueError(\"No data to train\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: GENERATING MEL-SPECTROGRAMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def audio_to_spectrogram(y, sr=22050, n_mels=128):\n",
    "    # Function for creating spectrograms from audio files\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db[..., np.newaxis]\n",
    "\n",
    "spectrograms = []\n",
    "for i, audio in enumerate(audio_data):\n",
    "    spectrograms.append(audio_to_spectrogram(audio))\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(audio_data)} spectrograms...\")\n",
    "\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "speakers = np.array(speakers)\n",
    "\n",
    "print(f\"\\nSpectrograms shape: {spectrograms.shape}\")\n",
    "\n",
    "def _get_recording_group_key(path, speaker):\n",
    "    \"\"\"\n",
    "    Given a relative path like 'accepted/p226/p226_003_000.wav',\n",
    "    return a deterministic group key.\n",
    "\n",
    "    For most speakers: group by (speaker, original_recording_id) where\n",
    "    original_recording_id is the middle number in 'p226_003_000'.\n",
    "\n",
    "    For accepted/p001: treat each file as its own group (no special grouping).\n",
    "    \"\"\"\n",
    "    norm_path = path.replace(\"\\\\\", \"/\")\n",
    "    basename = os.path.basename(norm_path)\n",
    "    stem, _ = os.path.splitext(basename)\n",
    "    parts = stem.split(\"_\")\n",
    "\n",
    "    # Special case: manual recordings\n",
    "    if \"/accepted/\" in norm_path and speaker == \"p001\":\n",
    "        return f\"{speaker}|{stem}\"\n",
    "\n",
    "    # Typical auto-split pattern: pXXX_###_###\n",
    "    if len(parts) >= 3 and parts[0] == speaker and parts[1].isdigit() and parts[2].isdigit():\n",
    "        # use the middle number as \"original recording\" id\n",
    "        original_id = parts[1]               \n",
    "        return f\"{speaker}|{original_id}\"\n",
    "\n",
    "\n",
    "\n",
    "def split_by_speaker_and_recording(\n",
    "    X, y, speakers,\n",
    "    train_ratio=0.7, val_ratio=0.15, test_ratio=0.15\n",
    "):\n",
    "    \"\"\"\n",
    "    3-way split:\n",
    "      - per speaker\n",
    "      - keeping all segments from the same original recording together\n",
    "      - except for manual recordings TODO why?\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking if data is loaded succesfully\n",
    "    if not (len(X) == len(y) == len(speakers)):\n",
    "        raise ValueError(\"X, y and speakers must have the same length\")\n",
    "\n",
    "    # We rely on the fact that each loaded sample corresponds to the same row in df.\n",
    "    # If some files failed to load, we stop rather than mis-align.\n",
    "    if 'failed' in globals() and failed != 0:\n",
    "        raise ValueError(\n",
    "            \"Splitting assumes all files loaded successfully (failed == 0). \"\n",
    "            \"Got failed != 0; please adjust loading logic or splitting.\"\n",
    "        )\n",
    "    if len(df) != len(X):\n",
    "        raise ValueError(\n",
    "            f\"Length mismatch between df ({len(df)}) and data ({len(X)}). \"\n",
    "            \"Splitting by recording cannot be done safely.\"\n",
    "        )\n",
    "\n",
    "    # Build groups: (speaker, recording_group_key) -> list of sample indices\n",
    "    groups_per_speaker = {} \n",
    "    for idx, spk in enumerate(speakers):\n",
    "        path = df.loc[idx, \"path\"]\n",
    "        group_key = _get_recording_group_key(path, spk)\n",
    "\n",
    "        if spk not in groups_per_speaker:\n",
    "            groups_per_speaker[spk] = {}\n",
    "        if group_key not in groups_per_speaker[spk]:\n",
    "            groups_per_speaker[spk][group_key] = []\n",
    "        groups_per_speaker[spk][group_key].append(idx)\n",
    "\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "\n",
    "    for spk in sorted(groups_per_speaker.keys()):\n",
    "        group_dict = groups_per_speaker[spk]\n",
    "        grouped_items = sorted(group_dict.items(), key=lambda kv: kv[0])\n",
    "\n",
    "        # Total samples for this speaker\n",
    "        all_indices = [i for _, idxs in grouped_items for i in idxs]\n",
    "        n_total = len(all_indices)\n",
    "\n",
    "        target_train = int(round(train_ratio * n_total))\n",
    "        target_val = int(round(val_ratio * n_total))\n",
    "        n_train = n_val = 0\n",
    "\n",
    "        for group_key, idxs in grouped_items:\n",
    "            gsize = len(idxs)\n",
    "\n",
    "            if n_train + gsize <= target_train:\n",
    "                train_idx.extend(idxs)\n",
    "                n_train += gsize\n",
    "            elif n_val + gsize <= target_val:\n",
    "                val_idx.extend(idxs)\n",
    "                n_val += gsize\n",
    "            else:\n",
    "                test_idx.extend(idxs)\n",
    "\n",
    "    train_idx = np.array(sorted(train_idx))\n",
    "    val_idx = np.array(sorted(val_idx))\n",
    "    test_idx = np.array(sorted(test_idx))\n",
    "\n",
    "    return (\n",
    "        X[train_idx], X[val_idx], X[test_idx],\n",
    "        y[train_idx], y[val_idx], y[test_idx]\n",
    "    )\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_by_speaker_and_recording(\n",
    "    spectrograms,\n",
    "    labels,\n",
    "    speakers,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    test_ratio=TEST_RATIO\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal split sizes:\")\n",
    "print(f\"  Train:      {X_train.shape[0]}\")\n",
    "print(f\"  Validation: {X_val.shape[0]}\")\n",
    "print(f\"  Test:       {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f39dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: BUILDING AND TRAINING CNN\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m3\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,194,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,287,236</span> (16.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,287,236\u001b[0m (16.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,287,233</span> (16.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,287,233\u001b[0m (16.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (16.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (16.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 212ms/step - accuracy: 0.6979 - loss: 0.5671 - val_accuracy: 0.7540 - val_loss: 0.5440\n",
      "Epoch 2/15\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 231ms/step - accuracy: 0.8606 - loss: 0.3282 - val_accuracy: 0.8367 - val_loss: 0.3606\n",
      "Epoch 3/15\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 225ms/step - accuracy: 0.8938 - loss: 0.2481 - val_accuracy: 0.8730 - val_loss: 0.2965\n",
      "Epoch 4/15\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 214ms/step - accuracy: 0.9422 - loss: 0.1478 - val_accuracy: 0.8750 - val_loss: 0.3057\n",
      "Epoch 5/15\n",
      "\u001b[1m140/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 0.9548 - loss: 0.1182"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: BUILDING AND TRAINING CNN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "\n",
    "# Building models\n",
    "\n",
    "def build_cnn_model(input_shape, norm):\n",
    "    # default model (without dropout or anything)\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        norm,\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "def build_cnn_model_dropout(input_shape, norm):\n",
    "    # model with dropout\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        norm,\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "def build_cnn_model_dropout_low(input_shape, norm):\n",
    "    # model with low dropout (for comparison)\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        norm,\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "\n",
    "# Checking which model to use\n",
    "if (dropout):\n",
    "    model = build_cnn_model_dropout(X_train.shape[1:], norm_layer)\n",
    "elif(dropout_low):\n",
    "    model = build_cnn_model_dropout_low(X_train.shape[1:], norm_layer)\n",
    "else:\n",
    "    model = build_cnn_model(X_train.shape[1:], norm_layer)\n",
    "\n",
    "# Show model\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# If training is fast, we can stop early\n",
    "# TODO check if values can be improved\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: EVALUATION AND RESULTS (ON TEST SET)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "#Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nTEST ACCURACY: {test_accuracy*100:.2f}%\\n\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Rejected', 'Accepted']))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Test Set)', fontsize=16, fontweight='bold')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['Rejected', 'Accepted']\n",
    "plt.xticks([0, 1], classes)\n",
    "plt.yticks([0, 1], classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'true_label': y_test,\n",
    "    'predicted_label': y_test_pred,\n",
    "    'confidence': y_test_pred_prob.flatten()\n",
    "})\n",
    "results_df.to_csv('test_results.csv', index=False)\n",
    "\n",
    "# Saving model\n",
    "model.save('speaker_verification_model.h5')\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  • training_history.png\")\n",
    "print(\"  • confusion_matrix.png\")\n",
    "print(\"  • test_results.csv\")\n",
    "print(\"  • speaker_verification_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: BUILDING AND TRAINING CNN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "\n",
    "# Building models\n",
    "\n",
    "def build_cnn_model(input_shape, norm):\n",
    "    # default model (without dropout or anything)\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        norm,\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "def build_cnn_model_dropout(input_shape, norm):\n",
    "    # model with dropout\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        norm,\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "def build_cnn_model_dropout_low(input_shape, norm):\n",
    "    # model with low dropout (for comparison)\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        norm,\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "\n",
    "# Checking which model to use\n",
    "if (dropout):\n",
    "    model = build_cnn_model_dropout(X_train.shape[1:], norm_layer)\n",
    "elif(dropout_low):\n",
    "    model = build_cnn_model_dropout_low(X_train.shape[1:], norm_layer)\n",
    "else:\n",
    "    model = build_cnn_model(X_train.shape[1:], norm_layer)\n",
    "\n",
    "# Show model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(learning_rate=1e-2, momentum=0.9)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# If training is fast, we can stop early\n",
    "# TODO check if values can be improved\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: EVALUATION AND RESULTS (ON TEST SET)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "#Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nTEST ACCURACY: {test_accuracy*100:.2f}%\\n\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Rejected', 'Accepted']))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Test Set)', fontsize=16, fontweight='bold')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['Rejected', 'Accepted']\n",
    "plt.xticks([0, 1], classes)\n",
    "plt.yticks([0, 1], classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'true_label': y_test,\n",
    "    'predicted_label': y_test_pred,\n",
    "    'confidence': y_test_pred_prob.flatten()\n",
    "})\n",
    "results_df.to_csv('test_results.csv', index=False)\n",
    "\n",
    "# Saving model\n",
    "model.save('speaker_verification_model.h5')\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  • training_history.png\")\n",
    "print(\"  • confusion_matrix.png\")\n",
    "print(\"  • test_results.csv\")\n",
    "print(\"  • speaker_verification_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884dc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d2456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
