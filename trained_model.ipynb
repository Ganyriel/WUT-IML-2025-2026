{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df39a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GENERATING MANIFEST.CSV\n",
      "======================================================================\n",
      "\n",
      " Base path: data_recordings\n",
      "\n",
      " Processing ACCEPTED...\n",
      "p001: 242 files\n",
      "p239: 900 files\n",
      "p243: 900 files\n",
      "p259: 901 files\n",
      "p268: 901 files\n",
      "p270: 900 files\n",
      "\n",
      "Processing REJECTED...\n",
      "  p226: 302 files\n",
      "  p227: 300 files\n",
      "  p228: 300 files\n",
      "  p230: 301 files\n",
      "  p231: 300 files\n",
      "  p232: 300 files\n",
      "  p233: 301 files\n",
      "  p236: 300 files\n",
      "  p244: 300 files\n",
      "  p250: 300 files\n",
      "  p254: 300 files\n",
      "  p256: 300 files\n",
      "  p257: 300 files\n",
      "  p258: 300 files\n",
      "  p267: 300 files\n",
      "  p269: 300 files\n",
      "  p273: 300 files\n",
      "  p274: 300 files\n",
      "  p276: 300 files\n",
      "  p277: 301 files\n",
      "\n",
      "======================================================================\n",
      "MANIFEST GENERAED SUCCESFULLY\n",
      "======================================================================\n",
      "\n",
      "Archive: data_recordings\\manifest.csv\n",
      "Total archives: 10749\n",
      "  • Accepted (label=1): 4744\n",
      "  • Rejected (label=0): 6005\n",
      "\n",
      "First 5 rows:\n",
      "  speaker_id                        path  label\n",
      "0       p001  accepted\\p001\\p001_001.wav      1\n",
      "1       p001  accepted\\p001\\p001_002.wav      1\n",
      "2       p001  accepted\\p001\\p001_003.wav      1\n",
      "3       p001  accepted\\p001\\p001_004.wav      1\n",
      "4       p001  accepted\\p001\\p001_005.wav      1\n",
      "\n",
      "Columns: ['speaker_id', 'path', 'label']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING MANIFEST.CSV\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Data path\n",
    "base_path = r'data_recordings'\n",
    "\n",
    "print(f\"\\n Base path: {base_path}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "print(\"\\n Processing ACCEPTED...\")\n",
    "accepted_folder = os.path.join(base_path, 'accepted')\n",
    "if os.path.exists(accepted_folder):\n",
    "    for speaker_folder in os.listdir(accepted_folder):\n",
    "        speaker_path = os.path.join(accepted_folder, speaker_folder)\n",
    "        if os.path.isdir(speaker_path):\n",
    "            file_count = 0\n",
    "            for file in os.listdir(speaker_path):\n",
    "                if file.endswith(('.wav', '.mp3', '.flac')):\n",
    "                    relative_path = os.path.join('accepted', speaker_folder, file)\n",
    "                    rows.append({\n",
    "                        'speaker_id': speaker_folder,\n",
    "                        'path': relative_path,\n",
    "                        'label': 1  # 1 = ACCEPTED\n",
    "                    })\n",
    "                    file_count += 1\n",
    "            print(f\"{speaker_folder}: {file_count} files\")\n",
    "else:\n",
    "    print(f\"Not found: {accepted_folder}\")\n",
    "\n",
    "print(\"\\nProcessing REJECTED...\")\n",
    "rejected_folder = os.path.join(base_path, 'rejected')\n",
    "if os.path.exists(rejected_folder):\n",
    "    for speaker_folder in os.listdir(rejected_folder):\n",
    "        speaker_path = os.path.join(rejected_folder, speaker_folder)\n",
    "        if os.path.isdir(speaker_path):\n",
    "            file_count = 0\n",
    "            for file in os.listdir(speaker_path):\n",
    "                if file.endswith(('.wav', '.mp3', '.flac')):\n",
    "                    relative_path = os.path.join('rejected', speaker_folder, file)\n",
    "                    rows.append({\n",
    "                        'speaker_id': speaker_folder,\n",
    "                        'path': relative_path,\n",
    "                        'label': 0  # 0 = REJECTED\n",
    "                    })\n",
    "                    file_count += 1\n",
    "            print(f\"  {speaker_folder}: {file_count} files\")\n",
    "else:\n",
    "    print(f\" Not found: {rejected_folder}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "manifest_file = os.path.join(base_path, 'manifest.csv')\n",
    "df.to_csv(manifest_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MANIFEST GENERAED SUCCESFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nArchive: {manifest_file}\")\n",
    "print(f\"Total archives: {len(df)}\")\n",
    "print(f\"  • Accepted (label=1): {sum(df['label'] == 1)}\")\n",
    "print(f\"  • Rejected (label=0): {sum(df['label'] == 0)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7b41d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SPEAKER VERIFICATION - CNN WITH MEL-SPECTROGRAMS\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  Base path: data_recordings\n",
      "  Manifest: data_recordings\\manifest.csv\n",
      "  Max samples: All\n",
      "  Split ratios (train/val/test): 0.7/0.15/0.15\n",
      "\n",
      "======================================================================\n",
      "VERIFYING FILES AND PATHS\n",
      "======================================================================\n",
      "Base folder found\n",
      "Manifest found\n",
      "\n",
      "======================================================================\n",
      "STEP 1: LOADING DATA FROM MANIFEST.CSV\n",
      "======================================================================\n",
      "\n",
      "Total entries: 10749\n",
      "\n",
      "First 5 rows:\n",
      "  speaker_id                        path  label\n",
      "0       p001  accepted\\p001\\p001_001.wav      1\n",
      "1       p001  accepted\\p001\\p001_002.wav      1\n",
      "2       p001  accepted\\p001\\p001_003.wav      1\n",
      "3       p001  accepted\\p001\\p001_004.wav      1\n",
      "4       p001  accepted\\p001\\p001_005.wav      1\n",
      "\n",
      "Class distribution:\n",
      "  Accepted: 4744\n",
      "  Rejected: 6005\n",
      "\n",
      "Number of unique speakers: 26\n",
      "Sample speakers: ['p001' 'p239' 'p243' 'p259' 'p268' 'p270' 'p226' 'p227' 'p228' 'p230']\n",
      "\n",
      "======================================================================\n",
      "STEP 2: LOADING AUDIO FILES\n",
      "======================================================================\n",
      "  Processed 50/10749 files...\n",
      "  Processed 100/10749 files...\n",
      "  Processed 150/10749 files...\n",
      "  Processed 200/10749 files...\n",
      "  Processed 250/10749 files...\n",
      "  Processed 300/10749 files...\n",
      "  Processed 350/10749 files...\n",
      "  Processed 400/10749 files...\n",
      "  Processed 450/10749 files...\n",
      "  Processed 500/10749 files...\n",
      "  Processed 550/10749 files...\n",
      "  Processed 600/10749 files...\n",
      "  Processed 650/10749 files...\n",
      "  Processed 700/10749 files...\n",
      "  Processed 750/10749 files...\n",
      "  Processed 800/10749 files...\n",
      "  Processed 850/10749 files...\n",
      "  Processed 900/10749 files...\n",
      "  Processed 950/10749 files...\n",
      "  Processed 1000/10749 files...\n",
      "  Processed 1050/10749 files...\n",
      "  Processed 1100/10749 files...\n",
      "  Processed 1150/10749 files...\n",
      "  Processed 1200/10749 files...\n",
      "  Processed 1250/10749 files...\n",
      "  Processed 1300/10749 files...\n",
      "  Processed 1350/10749 files...\n",
      "  Processed 1400/10749 files...\n",
      "  Processed 1450/10749 files...\n",
      "  Processed 1500/10749 files...\n",
      "  Processed 1550/10749 files...\n",
      "  Processed 1600/10749 files...\n",
      "  Processed 1650/10749 files...\n",
      "  Processed 1700/10749 files...\n",
      "  Processed 1750/10749 files...\n",
      "  Processed 1800/10749 files...\n",
      "  Processed 1850/10749 files...\n",
      "  Processed 1900/10749 files...\n",
      "  Processed 1950/10749 files...\n",
      "  Processed 2000/10749 files...\n",
      "  Processed 2050/10749 files...\n",
      "  Processed 2100/10749 files...\n",
      "  Processed 2150/10749 files...\n",
      "  Processed 2200/10749 files...\n",
      "  Processed 2250/10749 files...\n",
      "  Processed 2300/10749 files...\n",
      "  Processed 2350/10749 files...\n",
      "  Processed 2400/10749 files...\n",
      "  Processed 2450/10749 files...\n",
      "  Processed 2500/10749 files...\n",
      "  Processed 2550/10749 files...\n",
      "  Processed 2600/10749 files...\n",
      "  Processed 2650/10749 files...\n",
      "  Processed 2700/10749 files...\n",
      "  Processed 2750/10749 files...\n",
      "  Processed 2800/10749 files...\n",
      "  Processed 2850/10749 files...\n",
      "  Processed 2900/10749 files...\n",
      "  Processed 2950/10749 files...\n",
      "  Processed 3000/10749 files...\n",
      "  Processed 3050/10749 files...\n",
      "  Processed 3100/10749 files...\n",
      "  Processed 3150/10749 files...\n",
      "  Processed 3200/10749 files...\n",
      "  Processed 3250/10749 files...\n",
      "  Processed 3300/10749 files...\n",
      "  Processed 3350/10749 files...\n",
      "  Processed 3400/10749 files...\n",
      "  Processed 3450/10749 files...\n",
      "  Processed 3500/10749 files...\n",
      "  Processed 3550/10749 files...\n",
      "  Processed 3600/10749 files...\n",
      "  Processed 3650/10749 files...\n",
      "  Processed 3700/10749 files...\n",
      "  Processed 3750/10749 files...\n",
      "  Processed 3800/10749 files...\n",
      "  Processed 3850/10749 files...\n",
      "  Processed 3900/10749 files...\n",
      "  Processed 3950/10749 files...\n",
      "  Processed 4000/10749 files...\n",
      "  Processed 4050/10749 files...\n",
      "  Processed 4100/10749 files...\n",
      "  Processed 4150/10749 files...\n",
      "  Processed 4200/10749 files...\n",
      "  Processed 4250/10749 files...\n",
      "  Processed 4300/10749 files...\n",
      "  Processed 4350/10749 files...\n",
      "  Processed 4400/10749 files...\n",
      "  Processed 4450/10749 files...\n",
      "  Processed 4500/10749 files...\n",
      "  Processed 4550/10749 files...\n",
      "  Processed 4600/10749 files...\n",
      "  Processed 4650/10749 files...\n",
      "  Processed 4700/10749 files...\n",
      "  Processed 4750/10749 files...\n",
      "  Processed 4800/10749 files...\n",
      "  Processed 4850/10749 files...\n",
      "  Processed 4900/10749 files...\n",
      "  Processed 4950/10749 files...\n",
      "  Processed 5000/10749 files...\n",
      "  Processed 5050/10749 files...\n",
      "  Processed 5100/10749 files...\n",
      "  Processed 5150/10749 files...\n",
      "  Processed 5200/10749 files...\n",
      "  Processed 5250/10749 files...\n",
      "  Processed 5300/10749 files...\n",
      "  Processed 5350/10749 files...\n",
      "  Processed 5400/10749 files...\n",
      "  Processed 5450/10749 files...\n",
      "  Processed 5500/10749 files...\n",
      "  Processed 5550/10749 files...\n",
      "  Processed 5600/10749 files...\n",
      "  Processed 5650/10749 files...\n",
      "  Processed 5700/10749 files...\n",
      "  Processed 5750/10749 files...\n",
      "  Processed 5800/10749 files...\n",
      "  Processed 5850/10749 files...\n",
      "  Processed 5900/10749 files...\n",
      "  Processed 5950/10749 files...\n",
      "  Processed 6000/10749 files...\n",
      "  Processed 6050/10749 files...\n",
      "  Processed 6100/10749 files...\n",
      "  Processed 6150/10749 files...\n",
      "  Processed 6200/10749 files...\n",
      "  Processed 6250/10749 files...\n",
      "  Processed 6300/10749 files...\n",
      "  Processed 6350/10749 files...\n",
      "  Processed 6400/10749 files...\n",
      "  Processed 6450/10749 files...\n",
      "  Processed 6500/10749 files...\n",
      "  Processed 6550/10749 files...\n",
      "  Processed 6600/10749 files...\n",
      "  Processed 6650/10749 files...\n",
      "  Processed 6700/10749 files...\n",
      "  Processed 6750/10749 files...\n",
      "  Processed 6800/10749 files...\n",
      "  Processed 6850/10749 files...\n",
      "  Processed 6900/10749 files...\n",
      "  Processed 6950/10749 files...\n",
      "  Processed 7000/10749 files...\n",
      "  Processed 7050/10749 files...\n",
      "  Processed 7100/10749 files...\n",
      "  Processed 7150/10749 files...\n",
      "  Processed 7200/10749 files...\n",
      "  Processed 7250/10749 files...\n",
      "  Processed 7300/10749 files...\n",
      "  Processed 7350/10749 files...\n",
      "  Processed 7400/10749 files...\n",
      "  Processed 7450/10749 files...\n",
      "  Processed 7500/10749 files...\n",
      "  Processed 7550/10749 files...\n",
      "  Processed 7600/10749 files...\n",
      "  Processed 7650/10749 files...\n",
      "  Processed 7700/10749 files...\n",
      "  Processed 7750/10749 files...\n",
      "  Processed 7800/10749 files...\n",
      "  Processed 7850/10749 files...\n",
      "  Processed 7900/10749 files...\n",
      "  Processed 7950/10749 files...\n",
      "  Processed 8000/10749 files...\n",
      "  Processed 8050/10749 files...\n",
      "  Processed 8100/10749 files...\n",
      "  Processed 8150/10749 files...\n",
      "  Processed 8200/10749 files...\n",
      "  Processed 8250/10749 files...\n",
      "  Processed 8300/10749 files...\n",
      "  Processed 8350/10749 files...\n",
      "  Processed 8400/10749 files...\n",
      "  Processed 8450/10749 files...\n",
      "  Processed 8500/10749 files...\n",
      "  Processed 8550/10749 files...\n",
      "  Processed 8600/10749 files...\n",
      "  Processed 8650/10749 files...\n",
      "  Processed 8700/10749 files...\n",
      "  Processed 8750/10749 files...\n",
      "  Processed 8800/10749 files...\n",
      "  Processed 8850/10749 files...\n",
      "  Processed 8900/10749 files...\n",
      "  Processed 8950/10749 files...\n",
      "  Processed 9000/10749 files...\n",
      "  Processed 9050/10749 files...\n",
      "  Processed 9100/10749 files...\n",
      "  Processed 9150/10749 files...\n",
      "  Processed 9200/10749 files...\n",
      "  Processed 9250/10749 files...\n",
      "  Processed 9300/10749 files...\n",
      "  Processed 9350/10749 files...\n",
      "  Processed 9400/10749 files...\n",
      "  Processed 9450/10749 files...\n",
      "  Processed 9500/10749 files...\n",
      "  Processed 9550/10749 files...\n",
      "  Processed 9600/10749 files...\n",
      "  Processed 9650/10749 files...\n",
      "  Processed 9700/10749 files...\n",
      "  Processed 9750/10749 files...\n",
      "  Processed 9800/10749 files...\n",
      "  Processed 9850/10749 files...\n",
      "  Processed 9900/10749 files...\n",
      "  Processed 9950/10749 files...\n",
      "  Processed 10000/10749 files...\n",
      "  Processed 10050/10749 files...\n",
      "  Processed 10100/10749 files...\n",
      "  Processed 10150/10749 files...\n",
      "  Processed 10200/10749 files...\n",
      "  Processed 10250/10749 files...\n",
      "  Processed 10300/10749 files...\n",
      "  Processed 10350/10749 files...\n",
      "  Processed 10400/10749 files...\n",
      "  Processed 10450/10749 files...\n",
      "  Processed 10500/10749 files...\n",
      "  Processed 10550/10749 files...\n",
      "  Processed 10600/10749 files...\n",
      "  Processed 10650/10749 files...\n",
      "  Processed 10700/10749 files...\n",
      "\n",
      "Loading completed: 10749 files\n",
      "\n",
      "======================================================================\n",
      "STEP 3: GENERATING MEL-SPECTROGRAMS\n",
      "======================================================================\n",
      "  Processed 50/10749 spectrograms...\n",
      "  Processed 100/10749 spectrograms...\n",
      "  Processed 150/10749 spectrograms...\n",
      "  Processed 200/10749 spectrograms...\n",
      "  Processed 250/10749 spectrograms...\n",
      "  Processed 300/10749 spectrograms...\n",
      "  Processed 350/10749 spectrograms...\n",
      "  Processed 400/10749 spectrograms...\n",
      "  Processed 450/10749 spectrograms...\n",
      "  Processed 500/10749 spectrograms...\n",
      "  Processed 550/10749 spectrograms...\n",
      "  Processed 600/10749 spectrograms...\n",
      "  Processed 650/10749 spectrograms...\n",
      "  Processed 700/10749 spectrograms...\n",
      "  Processed 750/10749 spectrograms...\n",
      "  Processed 800/10749 spectrograms...\n",
      "  Processed 850/10749 spectrograms...\n",
      "  Processed 900/10749 spectrograms...\n",
      "  Processed 950/10749 spectrograms...\n",
      "  Processed 1000/10749 spectrograms...\n",
      "  Processed 1050/10749 spectrograms...\n",
      "  Processed 1100/10749 spectrograms...\n",
      "  Processed 1150/10749 spectrograms...\n",
      "  Processed 1200/10749 spectrograms...\n",
      "  Processed 1250/10749 spectrograms...\n",
      "  Processed 1300/10749 spectrograms...\n",
      "  Processed 1350/10749 spectrograms...\n",
      "  Processed 1400/10749 spectrograms...\n",
      "  Processed 1450/10749 spectrograms...\n",
      "  Processed 1500/10749 spectrograms...\n",
      "  Processed 1550/10749 spectrograms...\n",
      "  Processed 1600/10749 spectrograms...\n",
      "  Processed 1650/10749 spectrograms...\n",
      "  Processed 1700/10749 spectrograms...\n",
      "  Processed 1750/10749 spectrograms...\n",
      "  Processed 1800/10749 spectrograms...\n",
      "  Processed 1850/10749 spectrograms...\n",
      "  Processed 1900/10749 spectrograms...\n",
      "  Processed 1950/10749 spectrograms...\n",
      "  Processed 2000/10749 spectrograms...\n",
      "  Processed 2050/10749 spectrograms...\n",
      "  Processed 2100/10749 spectrograms...\n",
      "  Processed 2150/10749 spectrograms...\n",
      "  Processed 2200/10749 spectrograms...\n",
      "  Processed 2250/10749 spectrograms...\n",
      "  Processed 2300/10749 spectrograms...\n",
      "  Processed 2350/10749 spectrograms...\n",
      "  Processed 2400/10749 spectrograms...\n",
      "  Processed 2450/10749 spectrograms...\n",
      "  Processed 2500/10749 spectrograms...\n",
      "  Processed 2550/10749 spectrograms...\n",
      "  Processed 2600/10749 spectrograms...\n",
      "  Processed 2650/10749 spectrograms...\n",
      "  Processed 2700/10749 spectrograms...\n",
      "  Processed 2750/10749 spectrograms...\n",
      "  Processed 2800/10749 spectrograms...\n",
      "  Processed 2850/10749 spectrograms...\n",
      "  Processed 2900/10749 spectrograms...\n",
      "  Processed 2950/10749 spectrograms...\n",
      "  Processed 3000/10749 spectrograms...\n",
      "  Processed 3050/10749 spectrograms...\n",
      "  Processed 3100/10749 spectrograms...\n",
      "  Processed 3150/10749 spectrograms...\n",
      "  Processed 3200/10749 spectrograms...\n",
      "  Processed 3250/10749 spectrograms...\n",
      "  Processed 3300/10749 spectrograms...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 129\u001b[39m\n\u001b[32m    127\u001b[39m spectrograms = []\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, audio \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(audio_data):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     spectrograms.append(\u001b[43maudio_to_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % \u001b[32m50\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Processed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(audio_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m spectrograms...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36maudio_to_spectrogram\u001b[39m\u001b[34m(y, sr, n_mels)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maudio_to_spectrogram\u001b[39m(y, sr=\u001b[32m22050\u001b[39m, n_mels=\u001b[32m128\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     mel_spec = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mel_spec_db[..., np.newaxis]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\miniconda3\\envs\\wut\\Lib\\site-packages\\librosa\\feature\\spectral.py:2135\u001b[39m, in \u001b[36mmelspectrogram\u001b[39m\u001b[34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[39m\n\u001b[32m   2013\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmelspectrogram\u001b[39m(\n\u001b[32m   2014\u001b[39m     *,\n\u001b[32m   2015\u001b[39m     y: Optional[np.ndarray] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2025\u001b[39m     **kwargs: Any,\n\u001b[32m   2026\u001b[39m ) -> np.ndarray:\n\u001b[32m   2027\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[32m   2028\u001b[39m \n\u001b[32m   2029\u001b[39m \u001b[33;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2133\u001b[39m \u001b[33;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[32m   2134\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2135\u001b[39m     S, n_fft = \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2136\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2147\u001b[39m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[32m   2148\u001b[39m     mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\miniconda3\\envs\\wut\\Lib\\site-packages\\librosa\\core\\spectrum.py:2945\u001b[39m, in \u001b[36m_spectrogram\u001b[39m\u001b[34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[39m\n\u001b[32m   2939\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2940\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[32m   2941\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2942\u001b[39m         )\n\u001b[32m   2943\u001b[39m     S = (\n\u001b[32m   2944\u001b[39m         np.abs(\n\u001b[32m-> \u001b[39m\u001b[32m2945\u001b[39m             \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2946\u001b[39m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2947\u001b[39m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2948\u001b[39m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2949\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2950\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2951\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2952\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2953\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2954\u001b[39m         )\n\u001b[32m   2955\u001b[39m         ** power\n\u001b[32m   2956\u001b[39m     )\n\u001b[32m   2958\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\miniconda3\\envs\\wut\\Lib\\site-packages\\librosa\\core\\spectrum.py:387\u001b[39m, in \u001b[36mstft\u001b[39m\u001b[34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bl_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, y_frames.shape[-\u001b[32m1\u001b[39m], n_columns):\n\u001b[32m    385\u001b[39m     bl_t = \u001b[38;5;28mmin\u001b[39m(bl_s + n_columns, y_frames.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     stft_matrix[..., bl_s + off_start : bl_t + off_start] = \u001b[43mfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfft_window\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43my_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbl_s\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbl_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stft_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\miniconda3\\envs\\wut\\Lib\\site-packages\\scipy\\fft\\_backend.py:18\u001b[39m, in \u001b[36m_ScipyBackend.__ua_function__\u001b[39m\u001b[34m(method, args, kwargs)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The default backend for fft calculations\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[33;03mNotes\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33;03mbackend for ``numpy`` and have it implement ``numpy.scipy.fft`` as well.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m __ua_domain__ = \u001b[33m\"\u001b[39m\u001b[33mnumpy.scipy.fft\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__ua_function__\u001b[39m(method, args, kwargs):\n\u001b[32m     21\u001b[39m     fn = \u001b[38;5;28mgetattr\u001b[39m(_basic_backend, method.\u001b[34m__name__\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split   # kept, though no longer used\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SPEAKER VERIFICATION - CNN WITH MEL-SPECTROGRAMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "base_path = r'data_recordings'\n",
    "manifest_path = os.path.join(base_path, 'manifest.csv')\n",
    "MAX_SAMPLES = None\n",
    "\n",
    "# ### Ratios for 3-way split\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Base path: {base_path}\")\n",
    "print(f\"  Manifest: {manifest_path}\")\n",
    "print(f\"  Max samples: {MAX_SAMPLES if MAX_SAMPLES else 'All'}\")\n",
    "print(f\"  Split ratios (train/val/test): {TRAIN_RATIO}/{VAL_RATIO}/{TEST_RATIO}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VERIFYING FILES AND PATHS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    raise FileNotFoundError(f\"Base folder not found: {base_path}\")\n",
    "\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(\"\\nPlease run first: python run_pipeline_to_get_data.py\")\n",
    "    raise FileNotFoundError(\"manifest.csv not found\")\n",
    "\n",
    "print(\"Base folder found\")\n",
    "print(\"Manifest found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 1: LOADING DATA FROM MANIFEST.CSV\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df = pd.read_csv(manifest_path)\n",
    "print(f\"\\nTotal entries: {len(df)}\")\n",
    "\n",
    "if MAX_SAMPLES:\n",
    "    df = df.head(MAX_SAMPLES)\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "if 'path' not in df.columns or 'label' not in df.columns:\n",
    "    raise ValueError(\"Incorrect manifest format\")\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Accepted: {sum(df['label'] == 1)}\")\n",
    "print(f\"  Rejected: {sum(df['label'] == 0)}\")\n",
    "\n",
    "# ### Extract speaker ID from the path\n",
    "# Assumes something like: accepted/p001/file.wav  -> speaker 'p001'\n",
    "df['speaker'] = df['path'].apply(lambda p: os.path.basename(os.path.dirname(p)))\n",
    "\n",
    "print(\"\\nNumber of unique speakers:\", df['speaker'].nunique())\n",
    "print(\"Sample speakers:\", df['speaker'].unique()[:10])\n",
    "\n",
    "def load_audio_file(file_path, base_folder, sr=22050, max_duration=3):\n",
    "    full_path = os.path.join(base_folder, file_path)\n",
    "    try:\n",
    "        y, _ = librosa.load(full_path, sr=sr, duration=max_duration)\n",
    "        y = y / (np.max(np.abs(y)) + 1e-6)\n",
    "        y, _ = librosa.effects.trim(y, top_db=20)\n",
    "        \n",
    "        target_length = sr * max_duration\n",
    "        if len(y) < target_length:\n",
    "            y = np.pad(y, (0, target_length - len(y)))\n",
    "        else:\n",
    "            y = y[:target_length]\n",
    "        return y\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: LOADING AUDIO FILES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "audio_data = []\n",
    "labels = []\n",
    "speakers = []   # ### keep track of speaker for each loaded sample\n",
    "failed = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    audio = load_audio_file(row['path'], base_path)\n",
    "    if audio is not None:\n",
    "        audio_data.append(audio)\n",
    "        labels.append(row['label'])\n",
    "        speakers.append(row['speaker'])\n",
    "    else:\n",
    "        failed += 1\n",
    "    \n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(df)} files...\")\n",
    "\n",
    "print(f\"\\nLoading completed: {len(audio_data)} files\")\n",
    "if failed > 0:\n",
    "    print(f\"Failed: {failed}\")\n",
    "\n",
    "if len(audio_data) == 0:\n",
    "    raise ValueError(\"No data to train\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: GENERATING MEL-SPECTROGRAMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def audio_to_spectrogram(y, sr=22050, n_mels=128):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db[..., np.newaxis]\n",
    "\n",
    "spectrograms = []\n",
    "for i, audio in enumerate(audio_data):\n",
    "    spectrograms.append(audio_to_spectrogram(audio))\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(audio_data)} spectrograms...\")\n",
    "\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "speakers = np.array(speakers)\n",
    "\n",
    "print(f\"\\nSpectrograms shape: {spectrograms.shape}\")\n",
    "\n",
    "def _get_recording_group_key(path, speaker):\n",
    "    \"\"\"\n",
    "    Given a relative path like 'accepted/p226/p226_003_000.wav',\n",
    "    return a deterministic group key.\n",
    "\n",
    "    For most speakers: group by (speaker, original_recording_id) where\n",
    "    original_recording_id is the middle number in 'p226_003_000'.\n",
    "\n",
    "    For accepted/p001: treat each file as its own group (no special grouping).\n",
    "    \"\"\"\n",
    "    norm_path = path.replace(\"\\\\\", \"/\")\n",
    "    basename = os.path.basename(norm_path)\n",
    "    stem, _ = os.path.splitext(basename)\n",
    "    parts = stem.split(\"_\")\n",
    "\n",
    "    # Special case: manual recordings\n",
    "    if \"/accepted/\" in norm_path and speaker == \"p001\":\n",
    "        return f\"{speaker}|{stem}\"\n",
    "\n",
    "    # Typical auto-split pattern: pXXX_###_###\n",
    "    if len(parts) >= 3 and parts[0] == speaker and parts[1].isdigit() and parts[2].isdigit():\n",
    "        # use the middle number as \"original recording\" id\n",
    "        original_id = parts[1]               \n",
    "        return f\"{speaker}|{original_id}\"\n",
    "\n",
    "\n",
    "\n",
    "def split_by_speaker_and_recording(\n",
    "    X, y, speakers,\n",
    "    train_ratio=0.7, val_ratio=0.15, test_ratio=0.15\n",
    "):\n",
    "    \"\"\"\n",
    "    3-way split:\n",
    "      - per speaker\n",
    "      - keeping all segments from the same original recording together\n",
    "      - except for manual recordings\n",
    "    \"\"\"\n",
    "\n",
    "    if not (len(X) == len(y) == len(speakers)):\n",
    "        raise ValueError(\"X, y and speakers must have the same length\")\n",
    "\n",
    "    # We rely on the fact that each loaded sample corresponds to the same row in df.\n",
    "    # If some files failed to load, we stop rather than mis-align.\n",
    "    if 'failed' in globals() and failed != 0:\n",
    "        raise ValueError(\n",
    "            \"Splitting assumes all files loaded successfully (failed == 0). \"\n",
    "            \"Got failed != 0; please adjust loading logic or splitting.\"\n",
    "        )\n",
    "    if len(df) != len(X):\n",
    "        raise ValueError(\n",
    "            f\"Length mismatch between df ({len(df)}) and data ({len(X)}). \"\n",
    "            \"Splitting by recording cannot be done safely.\"\n",
    "        )\n",
    "\n",
    "    # Build groups: (speaker, recording_group_key) -> list of sample indices\n",
    "    groups_per_speaker = {} \n",
    "    for idx, spk in enumerate(speakers):\n",
    "        path = df.loc[idx, \"path\"]\n",
    "        group_key = _get_recording_group_key(path, spk)\n",
    "\n",
    "        if spk not in groups_per_speaker:\n",
    "            groups_per_speaker[spk] = {}\n",
    "        if group_key not in groups_per_speaker[spk]:\n",
    "            groups_per_speaker[spk][group_key] = []\n",
    "        groups_per_speaker[spk][group_key].append(idx)\n",
    "\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "\n",
    "    for spk in sorted(groups_per_speaker.keys()):\n",
    "        group_dict = groups_per_speaker[spk]\n",
    "        grouped_items = sorted(group_dict.items(), key=lambda kv: kv[0])\n",
    "\n",
    "        # Total samples for this speaker\n",
    "        all_indices = [i for _, idxs in grouped_items for i in idxs]\n",
    "        n_total = len(all_indices)\n",
    "\n",
    "        target_train = int(round(train_ratio * n_total))\n",
    "        target_val = int(round(val_ratio * n_total))\n",
    "        n_train = n_val = 0\n",
    "\n",
    "        for group_key, idxs in grouped_items:\n",
    "            gsize = len(idxs)\n",
    "\n",
    "            if n_train + gsize <= target_train:\n",
    "                train_idx.extend(idxs)\n",
    "                n_train += gsize\n",
    "            elif n_val + gsize <= target_val:\n",
    "                val_idx.extend(idxs)\n",
    "                n_val += gsize\n",
    "            else:\n",
    "                test_idx.extend(idxs)\n",
    "\n",
    "    train_idx = np.array(sorted(train_idx))\n",
    "    val_idx = np.array(sorted(val_idx))\n",
    "    test_idx = np.array(sorted(test_idx))\n",
    "\n",
    "    return (\n",
    "        X[train_idx], X[val_idx], X[test_idx],\n",
    "        y[train_idx], y[val_idx], y[test_idx]\n",
    "    )\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_by_speaker_and_recording(\n",
    "    spectrograms,\n",
    "    labels,\n",
    "    speakers,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    test_ratio=TEST_RATIO\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal split sizes:\")\n",
    "print(f\"  Train:      {X_train.shape[0]}\")\n",
    "print(f\"  Validation: {X_val.shape[0]}\")\n",
    "print(f\"  Test:       {X_test.shape[0]}\")\n",
    "\n",
    "print(f\"\\nFinal split sizes:\")\n",
    "print(f\"  Train:      {X_train.shape[0]}\")\n",
    "print(f\"  Validation: {X_val.shape[0]}\")\n",
    "print(f\"  Test:       {X_test.shape[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: BUILDING AND TRAINING CNN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "def build_cnn_model(input_shape, norm):\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        norm,\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "model = build_cnn_model(X_train.shape[1:], norm_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: EVALUATION AND RESULTS (ON TEST SET)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nTEST ACCURACY: {test_accuracy*100:.2f}%\\n\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Rejected', 'Accepted']))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Test Set)', fontsize=16, fontweight='bold')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['Rejected', 'Accepted']\n",
    "plt.xticks([0, 1], classes)\n",
    "plt.yticks([0, 1], classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'true_label': y_test,\n",
    "    'predicted_label': y_test_pred,\n",
    "    'confidence': y_test_pred_prob.flatten()\n",
    "})\n",
    "results_df.to_csv('test_results.csv', index=False)\n",
    "\n",
    "model.save('speaker_verification_model.h5')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  • training_history.png\")\n",
    "print(\"  • confusion_matrix.png\")\n",
    "print(\"  • test_results.csv\")\n",
    "print(\"  • speaker_verification_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884dc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d2456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
