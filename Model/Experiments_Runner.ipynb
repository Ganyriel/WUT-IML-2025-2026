{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24997d625edf12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:35:57.617226200Z",
     "start_time": "2025-12-14T19:35:54.307510500Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Add path to Helpers to import model_utils\n",
    "sys.path.append(os.path.abspath('../Helpers'))\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3136a7e02d508f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:35:57.679178200Z",
     "start_time": "2025-12-14T19:35:57.618226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading manifest from: ../data_recordings\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "BASE_PATH = '../data_recordings'\n",
    "print(f\"Loading manifest from: {BASE_PATH}\")\n",
    "df = mu.load_manifest(BASE_PATH)\n",
    "\n",
    "# Optional: Sample data for quick debugging (uncomment next line)\n",
    "# df = df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d52fda978ca1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:37:04.990336400Z",
     "start_time": "2025-12-14T19:35:57.680177100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 11225 audio files...\n",
      "Successfully loaded: 11225, Failed: 0\n",
      "Generating Mel-Spectrograms...\n"
     ]
    }
   ],
   "source": [
    "# Load and process audio into spectrograms\n",
    "X, y, speakers = mu.load_and_process_data(df, BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3803da8c2fc4edee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:37:05.626690200Z",
     "start_time": "2025-12-14T19:37:04.991336500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7859, 128, 130, 1)\n",
      "Val shape:   (1681, 128, 130, 1)\n",
      "Test shape:  (1685, 128, 130, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Split Data ---\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, df_train, df_val, df_test = mu.split_dataset(X, y, speakers, df)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Val shape:   {X_val.shape}\")\n",
    "print(f\"Test shape:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7272101ccb35d1cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:37:05.636243300Z",
     "start_time": "2025-12-14T19:37:05.628691100Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. Define Experiments ---\n",
    "# (Experiment Name, Optimizer, Dropout, Base LR, lr_schedule, weight_decay, use_plateau)\n",
    "experiments = [\n",
    "    # --- your existing ones (unchanged behavior) ---\n",
    "    (\"Baseline_Adam\",   \"adam\",  0.0, 0.001,  None,     0.0,   False),\n",
    "    (\"Baseline_SGD\",    \"sgd\",   0.0, 0.01,   None,     0.0,   False),\n",
    "    (\"Dropout_0.2\",     \"adam\",  0.2, 0.001,  None,     0.0,   False),\n",
    "    (\"Low_LR_Adam\",     \"adam\",  0.0, 0.0001, None,     0.0,   False),\n",
    "\n",
    "    # --- up to 4 new ones ---\n",
    "    (\"Adam_Plateau\",        \"adam\",  0.2, 0.001, None,     0.0,   True),\n",
    "    (\"SGD_Plateau\",         \"sgd\",   0.0, 0.01,  None,     0.0,   True),\n",
    "    (\"AdamW_Cosine\",        \"adamw\", 0.2, 0.001, \"cosine\",  1e-4,  False),\n",
    "    (\"AdamW_Plateau\",       \"adamw\", 0.2, 0.001, None,     1e-4,  True),\n",
    "]\n",
    "results_summary = []\n",
    "# Create a directory for results if it doesn't exist\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f585ff885d5b8a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:18:41.506545100Z",
     "start_time": "2025-12-14T19:37:05.637244700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Running Experiment: Baseline_Adam\n",
      "Params: Opt=adam, Dropout=0.0, LR=0.001, Sched=None, WD=0.0, Plateau=False\n",
      "========================================\n",
      "Epoch 1/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 534ms/step - accuracy: 0.6151 - loss: 0.6545 - val_accuracy: 0.7008 - val_loss: 0.5658\n",
      "Epoch 2/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 539ms/step - accuracy: 0.8189 - loss: 0.3964 - val_accuracy: 0.8691 - val_loss: 0.2968\n",
      "Epoch 3/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 519ms/step - accuracy: 0.8843 - loss: 0.2705 - val_accuracy: 0.8471 - val_loss: 0.3240\n",
      "Epoch 4/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 518ms/step - accuracy: 0.9207 - loss: 0.1994 - val_accuracy: 0.9024 - val_loss: 0.2387\n",
      "Epoch 5/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 542ms/step - accuracy: 0.9415 - loss: 0.1503 - val_accuracy: 0.9179 - val_loss: 0.2052\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Test Accuracy: 0.9110\n",
      "Model saved to results/model_Baseline_Adam.keras\n",
      "Generating predictions for analysis...\n",
      "\n",
      "========================================\n",
      "Running Experiment: Adam_Plateau\n",
      "Params: Opt=adam, Dropout=0.2, LR=0.001, Sched=None, WD=0.0, Plateau=True\n",
      "========================================\n",
      "Epoch 1/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 578ms/step - accuracy: 0.6083 - loss: 0.6625 - val_accuracy: 0.6978 - val_loss: 0.5713 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 602ms/step - accuracy: 0.7605 - loss: 0.4961 - val_accuracy: 0.8328 - val_loss: 0.3718 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 627ms/step - accuracy: 0.8439 - loss: 0.3447 - val_accuracy: 0.9012 - val_loss: 0.2626 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 595ms/step - accuracy: 0.8834 - loss: 0.2764 - val_accuracy: 0.9078 - val_loss: 0.2430 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 599ms/step - accuracy: 0.9105 - loss: 0.2271 - val_accuracy: 0.9274 - val_loss: 0.2036 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Test Accuracy: 0.9187\n",
      "Model saved to results/model_Adam_Plateau.keras\n",
      "Generating predictions for analysis...\n",
      "Generating Monte Carlo Dropout predictions...\n",
      "\n",
      "--- MC Dropout Uncertainty Summary ---\n",
      "Mean uncertainty (std): 0.0962\n",
      "Median uncertainty:     0.0877\n",
      "Max uncertainty:        0.3160\n",
      "\n",
      "--- Uncertainty vs Correctness ---\n",
      "Mean uncertainty (correct preds): 0.0901\n",
      "Mean uncertainty (wrong preds):   0.1731\n",
      "\n",
      "========================================\n",
      "Running Experiment: AdamW_Cosine\n",
      "Params: Opt=adamw, Dropout=0.2, LR=0.001, Sched=cosine, WD=0.0001, Plateau=False\n",
      "========================================\n",
      "Epoch 1/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 1s/step - accuracy: 0.5876 - loss: 0.6841 - val_accuracy: 0.6847 - val_loss: 0.5973\n",
      "Epoch 2/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 748ms/step - accuracy: 0.7283 - loss: 0.5372 - val_accuracy: 0.7989 - val_loss: 0.4506\n",
      "Epoch 3/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 818ms/step - accuracy: 0.8174 - loss: 0.4007 - val_accuracy: 0.8721 - val_loss: 0.3194\n",
      "Epoch 4/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 717ms/step - accuracy: 0.8588 - loss: 0.3258 - val_accuracy: 0.8894 - val_loss: 0.2761\n",
      "Epoch 5/5\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 770ms/step - accuracy: 0.8715 - loss: 0.2943 - val_accuracy: 0.8953 - val_loss: 0.2698\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Test Accuracy: 0.8973\n",
      "Model saved to results/model_AdamW_Cosine.keras\n",
      "Generating predictions for analysis...\n",
      "Generating Monte Carlo Dropout predictions...\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Run Experiments Loop ---\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "steps_per_epoch = int(tf.math.ceil(len(X_train) / batch_size))\n",
    "\n",
    "for exp_name, opt, drop, lr, lr_sched, wd, use_plateau in [experiments[i] for i in [0, 4, 6]]:\n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(f\"Running Experiment: {exp_name}\")\n",
    "    print(f\"Params: Opt={opt}, Dropout={drop}, LR={lr}, Sched={lr_sched}, WD={wd}, Plateau={use_plateau}\")\n",
    "    print(\"=\"*40)\n",
    "    model = mu.build_model(\n",
    "        input_shape=X_train.shape[1:],\n",
    "        optimizer_name=opt,\n",
    "        dropout_rate=drop,\n",
    "        learning_rate=lr,\n",
    "        lr_schedule=lr_sched,\n",
    "        weight_decay=wd,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        total_epochs=epochs,\n",
    "        adapt_data=X_train\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "        tf.keras.callbacks.CSVLogger(f\"results/logs_{exp_name}.csv\"),\n",
    "        *mu.make_lr_callbacks(use_plateau=use_plateau),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Record results\n",
    "    results_summary.append({\n",
    "        \"Experiment\": exp_name,\n",
    "        \"Test_Accuracy\": acc,\n",
    "        \"Test_Loss\": loss,\n",
    "        \"Optimizer\": opt,\n",
    "        \"Dropout\": drop,\n",
    "        \"Learning_Rate\": lr\n",
    "    })\n",
    "\n",
    "    # Save Model\n",
    "    model_save_path = f\"results/model_{exp_name}.keras\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # --- IMPORTANT FOR EDA ---\n",
    "    # Save predictions with metadata for Error Analysis\n",
    "    print(\"Generating predictions for analysis...\")\n",
    "    preds_prob = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "    # Create DataFrame with true labels, predictions, AND metadata (filenames)\n",
    "    # We use df_test which we got from the split function\n",
    "    pred_df = df_test.copy()\n",
    "    pred_df[\"true_label\"] = y_test\n",
    "    pred_df[\"pred_prob\"] = preds_prob\n",
    "    pred_df[\"pred_label\"] = (preds_prob > 0.5).astype(int)\n",
    "\n",
    "    # Save to CSV\n",
    "    pred_df.to_csv(f\"results/predictions_{exp_name}.csv\", index=False)\n",
    "\n",
    "    if drop > 0:\n",
    "        print(\"Generating Monte Carlo Dropout predictions...\")\n",
    "        mc_mean, mc_std = mu.mc_dropout_predict(model, X_test, n_passes=30)\n",
    "\n",
    "        mc_df = df_test.copy()\n",
    "        mc_df[\"true_label\"] = y_test\n",
    "        mc_df[\"pred_prob_mean\"] = mc_mean\n",
    "        mc_df[\"pred_prob_std\"] = mc_std\n",
    "        mc_df[\"pred_label\"] = (mc_mean > 0.5).astype(int)\n",
    "\n",
    "        print(\"\\n--- MC Dropout Uncertainty Summary ---\")\n",
    "        print(f\"Mean uncertainty (std): {mc_std.mean():.4f}\")\n",
    "        print(f\"Median uncertainty:     {np.median(mc_std):.4f}\")\n",
    "        print(f\"Max uncertainty:        {mc_std.max():.4f}\")\n",
    "\n",
    "        correct_mask = (mc_df[\"pred_label\"].values == y_test)\n",
    "\n",
    "        mean_unc_correct = mc_std[correct_mask].mean()\n",
    "        mean_unc_wrong   = mc_std[~correct_mask].mean()\n",
    "\n",
    "        print(\"\\n--- Uncertainty vs Correctness ---\")\n",
    "        print(f\"Mean uncertainty (correct preds): {mean_unc_correct:.4f}\")\n",
    "        print(f\"Mean uncertainty (wrong preds):   {mean_unc_wrong:.4f}\")\n",
    "\n",
    "\n",
    "        mc_df.to_csv(f\"results/predictions_mc_{exp_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:18:41.540320600Z",
     "start_time": "2025-12-14T20:18:41.516320900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Experiments Summary ===\n",
      "      Experiment  Test_Accuracy  Test_Loss Optimizer  Dropout  Learning_Rate  \\\n",
      "0  Baseline_Adam       0.912166   0.198907      adam      0.0          0.001   \n",
      "1   Adam_Plateau       0.909199   0.227551      adam      0.2          0.001   \n",
      "2   AdamW_Cosine       0.879525   0.295540     adamw      0.2          0.001   \n",
      "\n",
      "             timestamp  \n",
      "0  2025-12-17 01:03:33  \n",
      "1  2025-12-17 01:03:33  \n",
      "2  2025-12-17 01:03:33  \n",
      "\n",
      "All experiments completed.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Summary ---\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "\n",
    "# Add a timestamp column with the current date and time\n",
    "summary_df['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(\"\\n=== Final Experiments Summary ===\")\n",
    "print(summary_df)\n",
    "\n",
    "summary_path = \"results/experiments_summary.csv\"\n",
    "\n",
    "# Check if file exists to determine whether to write the header\n",
    "# Note: If an old file exists without a 'timestamp' column, appending might cause\n",
    "# structure issues. It is best to delete the old file or manually add a column header to it.\n",
    "write_header = not os.path.exists(summary_path)\n",
    "\n",
    "# Save to CSV with mode='a' (append)\n",
    "summary_df.to_csv(summary_path, mode='a', header=write_header, index=False)\n",
    "\n",
    "print(\"\\nAll experiments completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
