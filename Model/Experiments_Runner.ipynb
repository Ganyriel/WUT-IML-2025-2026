{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:45:02.933162100Z",
     "start_time": "2025-12-14T18:44:59.441565400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add path to Helpers to import model_utils\n",
    "sys.path.append(os.path.abspath('../Helpers'))\n",
    "import model_utils as mu"
   ],
   "id": "c24997d625edf12",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:45:03.027736900Z",
     "start_time": "2025-12-14T18:45:02.939161400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Load Data ---\n",
    "BASE_PATH = '../data_recordings'\n",
    "print(f\"Loading manifest from: {BASE_PATH}\")\n",
    "df = mu.load_manifest(BASE_PATH)\n",
    "\n",
    "# Optional: Sample data for quick debugging (uncomment next line)\n",
    "# df = df.head(50)"
   ],
   "id": "3136a7e02d508f9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading manifest from: ../data_recordings\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:46:10.594291400Z",
     "start_time": "2025-12-14T18:45:03.029737500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and process audio into spectrograms\n",
    "X, y, speakers = mu.load_and_process_data(df, BASE_PATH)"
   ],
   "id": "a4d52fda978ca1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 11225 audio files...\n",
      "Successfully loaded: 11225, Failed: 0\n",
      "Generating Mel-Spectrograms...\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:46:11.206575200Z",
     "start_time": "2025-12-14T18:46:10.595291900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 2. Split Data ---\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, df_train, df_val, df_test = mu.split_dataset(X, y, speakers, df)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Val shape:   {X_val.shape}\")\n",
    "print(f\"Test shape:  {X_test.shape}\")"
   ],
   "id": "3803da8c2fc4edee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7859, 128, 130, 1)\n",
      "Val shape:   (1681, 128, 130, 1)\n",
      "Test shape:  (1685, 128, 130, 1)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:46:11.214632100Z",
     "start_time": "2025-12-14T18:46:11.207576400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3. Define Experiments ---\n",
    "# List of tuples: (Experiment Name, Optimizer, Dropout, Learning Rate)\n",
    "experiments = [\n",
    "    (\"Baseline_Adam\", \"adam\", 0.0, 0.001),\n",
    "    (\"Baseline_SGD\",  \"sgd\",  0.0, 0.01),\n",
    "    (\"Dropout_0.2\",   \"adam\", 0.2, 0.001),\n",
    "    (\"Low_LR_Adam\",   \"adam\", 0.0, 0.0001),\n",
    "]\n",
    "\n",
    "results_summary = []\n",
    "# Create a directory for results if it doesn't exist\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ],
   "id": "7272101ccb35d1cb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:18:11.096550700Z",
     "start_time": "2025-12-14T18:46:11.216631300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 4. Run Experiments Loop ---\n",
    "for exp_name, opt, drop, lr in experiments:\n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(f\"Running Experiment: {exp_name}\")\n",
    "    print(f\"Params: Opt={opt}, Dropout={drop}, LR={lr}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # Build model using helper function\n",
    "    model = mu.build_model(\n",
    "        input_shape=X_train.shape[1:],\n",
    "        optimizer_name=opt,\n",
    "        dropout_rate=drop,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    # Callbacks: Early Stopping and CSV Logger\n",
    "    log_path = f\"results/logs_{exp_name}.csv\"\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "        tf.keras.callbacks.CSVLogger(log_path)\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Record results\n",
    "    results_summary.append({\n",
    "        \"Experiment\": exp_name,\n",
    "        \"Test_Accuracy\": acc,\n",
    "        \"Test_Loss\": loss,\n",
    "        \"Optimizer\": opt,\n",
    "        \"Dropout\": drop,\n",
    "        \"Learning_Rate\": lr\n",
    "    })\n",
    "\n",
    "    # Save Model\n",
    "    model_save_path = f\"results/model_{exp_name}.h5\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # --- IMPORTANT FOR EDA ---\n",
    "    # Save predictions with metadata for Error Analysis\n",
    "    print(\"Generating predictions for analysis...\")\n",
    "    preds_prob = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "    # Create DataFrame with true labels, predictions, AND metadata (filenames)\n",
    "    # We use df_test which we got from the split function\n",
    "    pred_df = df_test.copy()\n",
    "    pred_df[\"true_label\"] = y_test\n",
    "    pred_df[\"pred_prob\"] = preds_prob\n",
    "    pred_df[\"pred_label\"] = (preds_prob > 0.5).astype(int)\n",
    "\n",
    "    # Save to CSV\n",
    "    pred_df.to_csv(f\"results/predictions_{exp_name}.csv\", index=False)"
   ],
   "id": "9f585ff885d5b8a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Running Experiment: Baseline_Adam\n",
      "Params: Opt=adam, Dropout=0.0, LR=0.001\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m38s\u001B[0m 152ms/step - accuracy: 0.6136 - loss: 1.6358 - val_accuracy: 0.6764 - val_loss: 0.6147\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 145ms/step - accuracy: 0.7118 - loss: 0.5537 - val_accuracy: 0.7852 - val_loss: 0.4482\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 130ms/step - accuracy: 0.7908 - loss: 0.4283 - val_accuracy: 0.8519 - val_loss: 0.3411\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.8384 - loss: 0.3566 - val_accuracy: 0.8572 - val_loss: 0.3215\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 125ms/step - accuracy: 0.8495 - loss: 0.3277 - val_accuracy: 0.8763 - val_loss: 0.2942\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.8672 - loss: 0.2966 - val_accuracy: 0.8995 - val_loss: 0.2320\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.7502 - loss: 0.4976 - val_accuracy: 0.7002 - val_loss: 0.5699\n",
      "Epoch 8/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 125ms/step - accuracy: 0.7327 - loss: 0.5304 - val_accuracy: 0.7323 - val_loss: 0.5097\n",
      "Epoch 9/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 127ms/step - accuracy: 0.7366 - loss: 0.5152 - val_accuracy: 0.7329 - val_loss: 0.5173\n",
      "Epoch 10/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.7464 - loss: 0.4964 - val_accuracy: 0.7240 - val_loss: 0.5159\n",
      "Epoch 11/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.7505 - loss: 0.4798 - val_accuracy: 0.7531 - val_loss: 0.4823\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8926\n",
      "Model saved to results/model_Baseline_Adam.h5\n",
      "Generating predictions for analysis...\n",
      "\n",
      "========================================\n",
      "Running Experiment: Baseline_SGD\n",
      "Params: Opt=sgd, Dropout=0.0, LR=0.01\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 116ms/step - accuracy: 0.5329 - loss: nan - val_accuracy: 0.5348 - val_loss: 0.6908\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 116ms/step - accuracy: 0.5349 - loss: 0.6909 - val_accuracy: 0.5348 - val_loss: 0.6907\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 113ms/step - accuracy: 0.5349 - loss: 0.6910 - val_accuracy: 0.5348 - val_loss: 0.6910\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 114ms/step - accuracy: 0.5349 - loss: 0.6910 - val_accuracy: 0.5348 - val_loss: 0.6907\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 114ms/step - accuracy: 0.5349 - loss: 0.6909 - val_accuracy: 0.5348 - val_loss: 0.6909\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 115ms/step - accuracy: 0.5349 - loss: 0.6910 - val_accuracy: 0.5348 - val_loss: 0.6907\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 115ms/step - accuracy: 0.5349 - loss: 0.6908 - val_accuracy: 0.5348 - val_loss: 0.6908\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5353\n",
      "Model saved to results/model_Baseline_SGD.h5\n",
      "Generating predictions for analysis...\n",
      "\n",
      "========================================\n",
      "Running Experiment: Dropout_0.2\n",
      "Params: Opt=adam, Dropout=0.2, LR=0.001\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 140ms/step - accuracy: 0.5681 - loss: 2.5391 - val_accuracy: 0.6669 - val_loss: 0.6300\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 138ms/step - accuracy: 0.6855 - loss: 0.6087 - val_accuracy: 0.7002 - val_loss: 0.5762\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 138ms/step - accuracy: 0.7068 - loss: 0.5670 - val_accuracy: 0.7329 - val_loss: 0.5197\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 137ms/step - accuracy: 0.7202 - loss: 0.5395 - val_accuracy: 0.7329 - val_loss: 0.5061\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 138ms/step - accuracy: 0.7224 - loss: 0.5271 - val_accuracy: 0.7246 - val_loss: 0.5194\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 137ms/step - accuracy: 0.7294 - loss: 0.5190 - val_accuracy: 0.7210 - val_loss: 0.5338\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 139ms/step - accuracy: 0.7374 - loss: 0.5075 - val_accuracy: 0.7603 - val_loss: 0.4651\n",
      "Epoch 8/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 138ms/step - accuracy: 0.7537 - loss: 0.4858 - val_accuracy: 0.8055 - val_loss: 0.4087\n",
      "Epoch 9/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 138ms/step - accuracy: 0.7497 - loss: 0.4841 - val_accuracy: 0.8055 - val_loss: 0.4111\n",
      "Epoch 10/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 139ms/step - accuracy: 0.7687 - loss: 0.4661 - val_accuracy: 0.7805 - val_loss: 0.4196\n",
      "Epoch 11/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 137ms/step - accuracy: 0.7898 - loss: 0.4277 - val_accuracy: 0.8495 - val_loss: 0.3525\n",
      "Epoch 12/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 138ms/step - accuracy: 0.8253 - loss: 0.3815 - val_accuracy: 0.8864 - val_loss: 0.2952\n",
      "Epoch 13/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 142ms/step - accuracy: 0.8488 - loss: 0.3463 - val_accuracy: 0.8899 - val_loss: 0.2663\n",
      "Epoch 14/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 152ms/step - accuracy: 0.8672 - loss: 0.3010 - val_accuracy: 0.9084 - val_loss: 0.2341\n",
      "Epoch 15/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 144ms/step - accuracy: 0.8946 - loss: 0.2599 - val_accuracy: 0.9340 - val_loss: 0.1756\n",
      "Epoch 16/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 152ms/step - accuracy: 0.9114 - loss: 0.2118 - val_accuracy: 0.9310 - val_loss: 0.1726\n",
      "Epoch 17/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 149ms/step - accuracy: 0.9235 - loss: 0.1935 - val_accuracy: 0.9459 - val_loss: 0.1437\n",
      "Epoch 18/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 145ms/step - accuracy: 0.9326 - loss: 0.1698 - val_accuracy: 0.9387 - val_loss: 0.1537\n",
      "Epoch 19/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 144ms/step - accuracy: 0.9341 - loss: 0.1695 - val_accuracy: 0.9393 - val_loss: 0.1528\n",
      "Epoch 20/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 147ms/step - accuracy: 0.9373 - loss: 0.1578 - val_accuracy: 0.9500 - val_loss: 0.1221\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9573\n",
      "Model saved to results/model_Dropout_0.2.h5\n",
      "Generating predictions for analysis...\n",
      "\n",
      "========================================\n",
      "Running Experiment: Low_LR_Adam\n",
      "Params: Opt=adam, Dropout=0.0, LR=0.0001\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 135ms/step - accuracy: 0.5922 - loss: 0.8267 - val_accuracy: 0.6627 - val_loss: 0.6215\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 129ms/step - accuracy: 0.6935 - loss: 0.5792 - val_accuracy: 0.7394 - val_loss: 0.5599\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 128ms/step - accuracy: 0.7624 - loss: 0.4992 - val_accuracy: 0.8001 - val_loss: 0.4665\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.8089 - loss: 0.4268 - val_accuracy: 0.8560 - val_loss: 0.3794\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 130ms/step - accuracy: 0.8748 - loss: 0.3161 - val_accuracy: 0.8590 - val_loss: 0.3527\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 137ms/step - accuracy: 0.8996 - loss: 0.2607 - val_accuracy: 0.8757 - val_loss: 0.3080\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 140ms/step - accuracy: 0.9158 - loss: 0.2202 - val_accuracy: 0.8959 - val_loss: 0.2495\n",
      "Epoch 8/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 139ms/step - accuracy: 0.9177 - loss: 0.2043 - val_accuracy: 0.8667 - val_loss: 0.3083\n",
      "Epoch 9/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 136ms/step - accuracy: 0.9252 - loss: 0.1825 - val_accuracy: 0.9191 - val_loss: 0.2014\n",
      "Epoch 10/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 129ms/step - accuracy: 0.9410 - loss: 0.1542 - val_accuracy: 0.9215 - val_loss: 0.1944\n",
      "Epoch 11/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 133ms/step - accuracy: 0.9446 - loss: 0.1494 - val_accuracy: 0.9209 - val_loss: 0.1908\n",
      "Epoch 12/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 132ms/step - accuracy: 0.9523 - loss: 0.1319 - val_accuracy: 0.9233 - val_loss: 0.1894\n",
      "Epoch 13/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 132ms/step - accuracy: 0.9509 - loss: 0.1294 - val_accuracy: 0.9244 - val_loss: 0.1814\n",
      "Epoch 14/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 145ms/step - accuracy: 0.9590 - loss: 0.1132 - val_accuracy: 0.9298 - val_loss: 0.1707\n",
      "Epoch 15/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 132ms/step - accuracy: 0.9612 - loss: 0.1044 - val_accuracy: 0.9161 - val_loss: 0.2107\n",
      "Epoch 16/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 133ms/step - accuracy: 0.9690 - loss: 0.0875 - val_accuracy: 0.9298 - val_loss: 0.1936\n",
      "Epoch 17/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 130ms/step - accuracy: 0.9728 - loss: 0.0802 - val_accuracy: 0.9358 - val_loss: 0.1672\n",
      "Epoch 18/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 129ms/step - accuracy: 0.9707 - loss: 0.0829 - val_accuracy: 0.9179 - val_loss: 0.2199\n",
      "Epoch 19/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 129ms/step - accuracy: 0.9781 - loss: 0.0677 - val_accuracy: 0.9334 - val_loss: 0.1669\n",
      "Epoch 20/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 129ms/step - accuracy: 0.9817 - loss: 0.0586 - val_accuracy: 0.9173 - val_loss: 0.2327\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9276\n",
      "Model saved to results/model_Low_LR_Adam.h5\n",
      "Generating predictions for analysis...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T19:18:11.125904400Z",
     "start_time": "2025-12-14T19:18:11.097550700Z"
    }
   },
   "source": [
    "# --- 5. Summary ---\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "print(\"\\n=== Final Experiments Summary ===\")\n",
    "print(summary_df)\n",
    "\n",
    "summary_path = \"results/experiments_summary.csv\"\n",
    "\n",
    "# Check if file exists to determine whether to write the header\n",
    "write_header = not os.path.exists(summary_path)\n",
    "\n",
    "# Save to CSV with mode='a' (append)\n",
    "summary_df.to_csv(summary_path, mode='a', header=write_header, index=False)\n",
    "\n",
    "print(\"\\nAll experiments completed.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Experiments Summary ===\n",
      "      Experiment  Test_Accuracy  Test_Loss Optimizer  Dropout  Learning_Rate\n",
      "0  Baseline_Adam       0.892582   0.250945      adam      0.0         0.0010\n",
      "1   Baseline_SGD       0.535312   0.690652       sgd      0.0         0.0100\n",
      "2    Dropout_0.2       0.957270   0.116995      adam      0.2         0.0010\n",
      "3    Low_LR_Adam       0.927596   0.176640      adam      0.0         0.0001\n",
      "\n",
      "All experiments completed.\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
