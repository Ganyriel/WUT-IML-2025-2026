{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:35:57.617226200Z",
     "start_time": "2025-12-14T19:35:54.307510500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "# Add path to Helpers to import model_utils\n",
    "sys.path.append(os.path.abspath('../Helpers'))\n",
    "import model_utils as mu"
   ],
   "id": "c24997d625edf12",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:35:57.679178200Z",
     "start_time": "2025-12-14T19:35:57.618226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Load Data ---\n",
    "BASE_PATH = '../data_recordings'\n",
    "print(f\"Loading manifest from: {BASE_PATH}\")\n",
    "df = mu.load_manifest(BASE_PATH)\n",
    "\n",
    "# Optional: Sample data for quick debugging (uncomment next line)\n",
    "# df = df.head(50)"
   ],
   "id": "3136a7e02d508f9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading manifest from: ../data_recordings\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:37:04.990336400Z",
     "start_time": "2025-12-14T19:35:57.680177100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and process audio into spectrograms\n",
    "X, y, speakers = mu.load_and_process_data(df, BASE_PATH)"
   ],
   "id": "a4d52fda978ca1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 11225 audio files...\n",
      "Successfully loaded: 11225, Failed: 0\n",
      "Generating Mel-Spectrograms...\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:37:05.626690200Z",
     "start_time": "2025-12-14T19:37:04.991336500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 2. Split Data ---\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, df_train, df_val, df_test = mu.split_dataset(X, y, speakers, df)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Val shape:   {X_val.shape}\")\n",
    "print(f\"Test shape:  {X_test.shape}\")"
   ],
   "id": "3803da8c2fc4edee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7859, 128, 130, 1)\n",
      "Val shape:   (1681, 128, 130, 1)\n",
      "Test shape:  (1685, 128, 130, 1)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:37:05.636243300Z",
     "start_time": "2025-12-14T19:37:05.628691100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3. Define Experiments ---\n",
    "# List of tuples: (Experiment Name, Optimizer, Dropout, Learning Rate)\n",
    "experiments = [\n",
    "    (\"Baseline_Adam\", \"adam\", 0.0, 0.001),\n",
    "    (\"Baseline_SGD\",  \"sgd\",  0.0, 0.01),\n",
    "    (\"Dropout_0.2\",   \"adam\", 0.2, 0.001),\n",
    "    (\"Low_LR_Adam\",   \"adam\", 0.0, 0.0001),\n",
    "]\n",
    "\n",
    "results_summary = []\n",
    "# Create a directory for results if it doesn't exist\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ],
   "id": "7272101ccb35d1cb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:18:41.506545100Z",
     "start_time": "2025-12-14T19:37:05.637244700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 4. Run Experiments Loop ---\n",
    "for exp_name, opt, drop, lr in experiments:\n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(f\"Running Experiment: {exp_name}\")\n",
    "    print(f\"Params: Opt={opt}, Dropout={drop}, LR={lr}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # Build model using helper function\n",
    "    model = mu.build_model(\n",
    "        input_shape=X_train.shape[1:],\n",
    "        optimizer_name=opt,\n",
    "        dropout_rate=drop,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    # Callbacks: Early Stopping and CSV Logger\n",
    "    log_path = f\"results/logs_{exp_name}.csv\"\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "        tf.keras.callbacks.CSVLogger(log_path)\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Record results\n",
    "    results_summary.append({\n",
    "        \"Experiment\": exp_name,\n",
    "        \"Test_Accuracy\": acc,\n",
    "        \"Test_Loss\": loss,\n",
    "        \"Optimizer\": opt,\n",
    "        \"Dropout\": drop,\n",
    "        \"Learning_Rate\": lr\n",
    "    })\n",
    "\n",
    "    # Save Model\n",
    "    model_save_path = f\"results/model_{exp_name}.keras\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # --- IMPORTANT FOR EDA ---\n",
    "    # Save predictions with metadata for Error Analysis\n",
    "    print(\"Generating predictions for analysis...\")\n",
    "    preds_prob = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "    # Create DataFrame with true labels, predictions, AND metadata (filenames)\n",
    "    # We use df_test which we got from the split function\n",
    "    pred_df = df_test.copy()\n",
    "    pred_df[\"true_label\"] = y_test\n",
    "    pred_df[\"pred_prob\"] = preds_prob\n",
    "    pred_df[\"pred_label\"] = (preds_prob > 0.5).astype(int)\n",
    "\n",
    "    # Save to CSV\n",
    "    pred_df.to_csv(f\"results/predictions_{exp_name}.csv\", index=False)"
   ],
   "id": "9f585ff885d5b8a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Running Experiment: Baseline_Adam\n",
      "Params: Opt=adam, Dropout=0.0, LR=0.001\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 130ms/step - accuracy: 0.6549 - loss: 1.3629 - val_accuracy: 0.7198 - val_loss: 0.5518\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 135ms/step - accuracy: 0.7486 - loss: 0.4963 - val_accuracy: 0.8251 - val_loss: 0.4108\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 143ms/step - accuracy: 0.8215 - loss: 0.3878 - val_accuracy: 0.7930 - val_loss: 0.4207\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 128ms/step - accuracy: 0.8633 - loss: 0.3173 - val_accuracy: 0.7579 - val_loss: 0.5195\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 137ms/step - accuracy: 0.9094 - loss: 0.2200 - val_accuracy: 0.9244 - val_loss: 0.1929\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 133ms/step - accuracy: 0.9338 - loss: 0.1649 - val_accuracy: 0.9369 - val_loss: 0.1635\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 131ms/step - accuracy: 0.9018 - loss: 0.2429 - val_accuracy: 0.7311 - val_loss: 0.4998\n",
      "Epoch 8/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 135ms/step - accuracy: 0.8943 - loss: 0.2437 - val_accuracy: 0.9203 - val_loss: 0.2035\n",
      "Epoch 9/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 134ms/step - accuracy: 0.9468 - loss: 0.1345 - val_accuracy: 0.9453 - val_loss: 0.1447\n",
      "Epoch 10/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 135ms/step - accuracy: 0.9579 - loss: 0.1101 - val_accuracy: 0.9233 - val_loss: 0.1964\n",
      "Epoch 11/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 134ms/step - accuracy: 0.9682 - loss: 0.0820 - val_accuracy: 0.9435 - val_loss: 0.1476\n",
      "Epoch 12/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 137ms/step - accuracy: 0.9696 - loss: 0.0770 - val_accuracy: 0.9393 - val_loss: 0.1651\n",
      "Epoch 13/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 135ms/step - accuracy: 0.9771 - loss: 0.0584 - val_accuracy: 0.9453 - val_loss: 0.1553\n",
      "Epoch 14/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 148ms/step - accuracy: 0.9737 - loss: 0.0703 - val_accuracy: 0.9482 - val_loss: 0.1408\n",
      "Epoch 15/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 137ms/step - accuracy: 0.9716 - loss: 0.0735 - val_accuracy: 0.9405 - val_loss: 0.1537\n",
      "Epoch 16/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.9849 - loss: 0.0399 - val_accuracy: 0.9530 - val_loss: 0.1392\n",
      "Epoch 17/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.9868 - loss: 0.0361 - val_accuracy: 0.9512 - val_loss: 0.1506\n",
      "Epoch 18/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 127ms/step - accuracy: 0.9891 - loss: 0.0293 - val_accuracy: 0.9465 - val_loss: 0.2025\n",
      "Epoch 19/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 129ms/step - accuracy: 0.9673 - loss: 0.0912 - val_accuracy: 0.9590 - val_loss: 0.1528\n",
      "Epoch 20/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 126ms/step - accuracy: 0.9878 - loss: 0.0343 - val_accuracy: 0.9399 - val_loss: 0.1840\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Test Accuracy: 0.9341\n",
      "Model saved to results/model_Baseline_Adam.keras\n",
      "Generating predictions for analysis...\n",
      "\n",
      "========================================\n",
      "Running Experiment: Baseline_SGD\n",
      "Params: Opt=sgd, Dropout=0.0, LR=0.01\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 118ms/step - accuracy: 0.5301 - loss: nan - val_accuracy: 0.5348 - val_loss: 0.6908\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 115ms/step - accuracy: 0.5349 - loss: 0.6909 - val_accuracy: 0.5348 - val_loss: 0.6909\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 116ms/step - accuracy: 0.5349 - loss: 0.6909 - val_accuracy: 0.5348 - val_loss: 0.6909\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 115ms/step - accuracy: 0.5349 - loss: 0.6908 - val_accuracy: 0.5348 - val_loss: 0.6911\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 116ms/step - accuracy: 0.5349 - loss: 0.6911 - val_accuracy: 0.5348 - val_loss: 0.6908\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 116ms/step - accuracy: 0.5349 - loss: 0.6910 - val_accuracy: 0.5348 - val_loss: 0.6908\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 117ms/step - accuracy: 0.5349 - loss: 0.6906 - val_accuracy: 0.5348 - val_loss: 0.6918\n",
      "Epoch 8/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 118ms/step - accuracy: 0.5349 - loss: 0.6911 - val_accuracy: 0.5348 - val_loss: 0.6911\n",
      "Epoch 9/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 120ms/step - accuracy: 0.5349 - loss: 0.6910 - val_accuracy: 0.5348 - val_loss: 0.6908\n",
      "Epoch 10/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 119ms/step - accuracy: 0.5349 - loss: 0.6909 - val_accuracy: 0.5348 - val_loss: 0.6908\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Test Accuracy: 0.5353\n",
      "Model saved to results/model_Baseline_SGD.keras\n",
      "Generating predictions for analysis...\n",
      "\n",
      "========================================\n",
      "Running Experiment: Dropout_0.2\n",
      "Params: Opt=adam, Dropout=0.2, LR=0.001\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 143ms/step - accuracy: 0.5192 - loss: 4.3911 - val_accuracy: 0.5348 - val_loss: 0.6915\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 141ms/step - accuracy: 0.5688 - loss: 0.6775 - val_accuracy: 0.6710 - val_loss: 0.6278\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 139ms/step - accuracy: 0.6718 - loss: 0.6255 - val_accuracy: 0.6817 - val_loss: 0.6405\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 141ms/step - accuracy: 0.6900 - loss: 0.5915 - val_accuracy: 0.7020 - val_loss: 0.5674\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 143ms/step - accuracy: 0.6897 - loss: 0.5795 - val_accuracy: 0.7180 - val_loss: 0.5472\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 142ms/step - accuracy: 0.6996 - loss: 0.5677 - val_accuracy: 0.7002 - val_loss: 0.5556\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 142ms/step - accuracy: 0.7095 - loss: 0.5563 - val_accuracy: 0.7008 - val_loss: 0.5483\n",
      "Epoch 8/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 142ms/step - accuracy: 0.7152 - loss: 0.5527 - val_accuracy: 0.7168 - val_loss: 0.5455\n",
      "Epoch 9/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 144ms/step - accuracy: 0.7208 - loss: 0.5387 - val_accuracy: 0.7198 - val_loss: 0.5107\n",
      "Epoch 10/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 144ms/step - accuracy: 0.7216 - loss: 0.5310 - val_accuracy: 0.7400 - val_loss: 0.5108\n",
      "Epoch 11/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 148ms/step - accuracy: 0.7343 - loss: 0.5091 - val_accuracy: 0.7478 - val_loss: 0.4699\n",
      "Epoch 12/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 177ms/step - accuracy: 0.7343 - loss: 0.5136 - val_accuracy: 0.7507 - val_loss: 0.4573\n",
      "Epoch 13/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 175ms/step - accuracy: 0.7467 - loss: 0.4853 - val_accuracy: 0.7478 - val_loss: 0.4771\n",
      "Epoch 14/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 165ms/step - accuracy: 0.7626 - loss: 0.4759 - val_accuracy: 0.8221 - val_loss: 0.3616\n",
      "Epoch 15/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 176ms/step - accuracy: 0.7540 - loss: 0.4907 - val_accuracy: 0.7960 - val_loss: 0.4232\n",
      "Epoch 16/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 149ms/step - accuracy: 0.7749 - loss: 0.4520 - val_accuracy: 0.7995 - val_loss: 0.4042\n",
      "Epoch 17/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 177ms/step - accuracy: 0.8074 - loss: 0.4050 - val_accuracy: 0.8727 - val_loss: 0.2987\n",
      "Epoch 18/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m38s\u001B[0m 153ms/step - accuracy: 0.8509 - loss: 0.3391 - val_accuracy: 0.9191 - val_loss: 0.2395\n",
      "Epoch 19/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 186ms/step - accuracy: 0.8571 - loss: 0.3200 - val_accuracy: 0.9054 - val_loss: 0.2260\n",
      "Epoch 20/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 180ms/step - accuracy: 0.8814 - loss: 0.2732 - val_accuracy: 0.9197 - val_loss: 0.2021\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Test Accuracy: 0.9205\n",
      "Model saved to results/model_Dropout_0.2.keras\n",
      "Generating predictions for analysis...\n",
      "\n",
      "========================================\n",
      "Running Experiment: Low_LR_Adam\n",
      "Params: Opt=adam, Dropout=0.0, LR=0.0001\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 167ms/step - accuracy: 0.5971 - loss: 0.8796 - val_accuracy: 0.6686 - val_loss: 0.6040\n",
      "Epoch 2/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 169ms/step - accuracy: 0.7093 - loss: 0.5527 - val_accuracy: 0.7668 - val_loss: 0.5053\n",
      "Epoch 3/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 164ms/step - accuracy: 0.7921 - loss: 0.4489 - val_accuracy: 0.8287 - val_loss: 0.4225\n",
      "Epoch 4/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 160ms/step - accuracy: 0.8535 - loss: 0.3466 - val_accuracy: 0.8537 - val_loss: 0.3617\n",
      "Epoch 5/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 168ms/step - accuracy: 0.8884 - loss: 0.2781 - val_accuracy: 0.8656 - val_loss: 0.3123\n",
      "Epoch 6/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 159ms/step - accuracy: 0.9104 - loss: 0.2359 - val_accuracy: 0.8911 - val_loss: 0.2649\n",
      "Epoch 7/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 170ms/step - accuracy: 0.9205 - loss: 0.2059 - val_accuracy: 0.9018 - val_loss: 0.2414\n",
      "Epoch 8/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 160ms/step - accuracy: 0.9335 - loss: 0.1759 - val_accuracy: 0.9167 - val_loss: 0.2140\n",
      "Epoch 9/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 151ms/step - accuracy: 0.9338 - loss: 0.1709 - val_accuracy: 0.8828 - val_loss: 0.2698\n",
      "Epoch 10/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 163ms/step - accuracy: 0.9481 - loss: 0.1431 - val_accuracy: 0.9149 - val_loss: 0.2047\n",
      "Epoch 11/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 171ms/step - accuracy: 0.9534 - loss: 0.1229 - val_accuracy: 0.9096 - val_loss: 0.2172\n",
      "Epoch 12/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 166ms/step - accuracy: 0.9603 - loss: 0.1098 - val_accuracy: 0.8876 - val_loss: 0.2757\n",
      "Epoch 13/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 164ms/step - accuracy: 0.9618 - loss: 0.1036 - val_accuracy: 0.8590 - val_loss: 0.4021\n",
      "Epoch 14/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 168ms/step - accuracy: 0.9607 - loss: 0.1035 - val_accuracy: 0.9310 - val_loss: 0.1777\n",
      "Epoch 15/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 165ms/step - accuracy: 0.9637 - loss: 0.0935 - val_accuracy: 0.9310 - val_loss: 0.1858\n",
      "Epoch 16/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 165ms/step - accuracy: 0.9785 - loss: 0.0646 - val_accuracy: 0.9185 - val_loss: 0.2164\n",
      "Epoch 17/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 167ms/step - accuracy: 0.9768 - loss: 0.0660 - val_accuracy: 0.9233 - val_loss: 0.2160\n",
      "Epoch 18/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 167ms/step - accuracy: 0.9784 - loss: 0.0654 - val_accuracy: 0.9215 - val_loss: 0.1985\n",
      "Epoch 19/20\n",
      "\u001B[1m246/246\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 147ms/step - accuracy: 0.9847 - loss: 0.0483 - val_accuracy: 0.9084 - val_loss: 0.2552\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Test Accuracy: 0.9205\n",
      "Model saved to results/model_Low_LR_Adam.keras\n",
      "Generating predictions for analysis...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T20:18:41.540320600Z",
     "start_time": "2025-12-14T20:18:41.516320900Z"
    }
   },
   "source": [
    "# --- 5. Summary ---\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "\n",
    "# Add a timestamp column with the current date and time\n",
    "summary_df['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(\"\\n=== Final Experiments Summary ===\")\n",
    "print(summary_df)\n",
    "\n",
    "summary_path = \"results/experiments_summary.csv\"\n",
    "\n",
    "# Check if file exists to determine whether to write the header\n",
    "# Note: If an old file exists without a 'timestamp' column, appending might cause\n",
    "# structure issues. It is best to delete the old file or manually add a column header to it.\n",
    "write_header = not os.path.exists(summary_path)\n",
    "\n",
    "# Save to CSV with mode='a' (append)\n",
    "summary_df.to_csv(summary_path, mode='a', header=write_header, index=False)\n",
    "\n",
    "print(\"\\nAll experiments completed.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Experiments Summary ===\n",
      "      Experiment  Test_Accuracy  Test_Loss Optimizer  Dropout  Learning_Rate  \\\n",
      "0  Baseline_Adam       0.934125   0.189988      adam      0.0         0.0010   \n",
      "1   Baseline_SGD       0.535312   0.690691       sgd      0.0         0.0100   \n",
      "2    Dropout_0.2       0.920475   0.202343      adam      0.2         0.0010   \n",
      "3    Low_LR_Adam       0.920475   0.196554      adam      0.0         0.0001   \n",
      "\n",
      "             timestamp  \n",
      "0  2025-12-14 21:18:41  \n",
      "1  2025-12-14 21:18:41  \n",
      "2  2025-12-14 21:18:41  \n",
      "3  2025-12-14 21:18:41  \n",
      "\n",
      "All experiments completed.\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
