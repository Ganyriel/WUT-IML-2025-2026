{
 "cells": [
  {
   "cell_type": "code",
   "id": "e35f733d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T19:19:47.332659900Z",
     "start_time": "2026-01-29T19:19:42.065246400Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../Model\"))\n",
    "import model_utils as mu\n",
    "\n",
    "BASE_PATH = '../data_recordings'\n",
    "RESULTS_DIR = '../Model/results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"AdamW_Plateau\"\n",
    "MODEL_PATH = os.path.join(RESULTS_DIR, f\"model_{MODEL_NAME}.keras\")\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Using SR:\", mu.SR, \"DURATION:\", mu.DURATION, \"TARGET_LENGTH:\", mu.TARGET_LENGTH)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "Using SR: 22050 DURATION: 3.0 TARGET_LENGTH: 66150\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2324a826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T19:21:08.433330400Z",
     "start_time": "2026-01-29T19:19:47.335657Z"
    }
   },
   "source": [
    "df = mu.load_manifest(BASE_PATH)\n",
    "X, y, speakers = mu.load_and_process_data(df, BASE_PATH)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, df_train, df_val, df_test = mu.split_dataset(X, y, speakers, df)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 11225 audio files...\n",
      "Successfully loaded: 11225, Failed: 0\n",
      "Generating Mel-Spectrograms...\n",
      "Train: (7859, 128, 130, 1) Val: (1681, 128, 130, 1) Test: (1685, 128, 130, 1)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "6a143214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T19:21:08.599282600Z",
     "start_time": "2026-01-29T19:21:08.442849700Z"
    }
   },
   "source": [
    "batch_size = 32\n",
    "epochs = 15\n",
    "steps_per_epoch = int(tf.math.ceil(len(X_train) / batch_size))\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Model already exists:\", MODEL_PATH)\n",
    "else:\n",
    "    model = mu.build_model(\n",
    "        input_shape=X_train.shape[1:],\n",
    "        optimizer_name=\"adamw\",\n",
    "        dropout_rate=0.2,\n",
    "        learning_rate=0.001,\n",
    "        lr_schedule=None,\n",
    "        weight_decay=1e-4,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        total_epochs=epochs,\n",
    "        adapt_data=X_train\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
    "        tf.keras.callbacks.CSVLogger(os.path.join(RESULTS_DIR, f\"logs_{MODEL_NAME}.csv\")),\n",
    "        *mu.make_lr_callbacks(use_plateau=True),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"Test Accuracy:\", acc, \"Test Loss:\", loss)\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"Saved:\", MODEL_PATH)\n",
    "\n",
    "    preds_prob = model.predict(X_test, verbose=0).flatten()\n",
    "    pred_df = df_test.copy()\n",
    "    pred_df[\"true_label\"] = y_test\n",
    "    pred_df[\"pred_prob\"] = preds_prob\n",
    "    pred_df[\"pred_label\"] = (preds_prob > 0.5).astype(int)\n",
    "    pred_df.to_csv(os.path.join(RESULTS_DIR, f\"predictions_{MODEL_NAME}.csv\"), index=False)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists: ../Model/results\\model_AdamW_Plateau.keras\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a4d9aacc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T19:21:09.386908400Z",
     "start_time": "2026-01-29T19:21:08.599282600Z"
    }
   },
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"Loaded:\", MODEL_PATH, \"Input shape:\", model.input_shape)\n",
    "\n",
    "dummy = np.zeros((1, model.input_shape[1], model.input_shape[2], 1), dtype=np.float32)\n",
    "_ = model.predict(dummy, verbose=0)\n",
    "print(\"Warmup OK\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../Model/results\\model_AdamW_Plateau.keras Input shape: (None, 128, 130, 1)\n",
      "Warmup OK\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "2b5b1c0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T19:21:16.343906800Z",
     "start_time": "2026-01-29T19:21:09.388906800Z"
    }
   },
   "source": [
    "import gradio as gr\n",
    "import librosa\n",
    "\n",
    "CAPTURE_SECONDS = 5\n",
    "THRESHOLD = 0.5\n",
    "SILENCE_TOP_DB = 35\n",
    "MIN_NON_SILENT_SECONDS = 0.5\n",
    "\n",
    "_, EXPECTED_MELS, EXPECTED_WIDTH, EXPECTED_CH = model.input_shape\n",
    "\n",
    "def _mono_float32(y):\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 2:\n",
    "        y = y.mean(axis=1)\n",
    "    y = y.astype(np.float32)\n",
    "    peak = float(np.max(np.abs(y))) if y.size else 0.0\n",
    "    if peak > 1.5:\n",
    "        y = y / (peak + 1e-6)\n",
    "    return y\n",
    "\n",
    "def _non_silent_seconds(y, sr):\n",
    "    intervals = librosa.effects.split(y, top_db=SILENCE_TOP_DB)\n",
    "    if len(intervals) == 0:\n",
    "        return 0.0\n",
    "    return float(sum((e - s) for s, e in intervals) / sr)\n",
    "\n",
    "def _make_model_input(y_proc, sr):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y_proc, sr=sr, n_mels=mu.N_MELS, fmax=mu.FMAX, hop_length=mu.HOP_LENGTH\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max).astype(np.float32)\n",
    "    if mel_db.shape[1] < EXPECTED_WIDTH:\n",
    "        mel_db = np.pad(mel_db, ((0,0),(0, EXPECTED_WIDTH - mel_db.shape[1])), mode=\"constant\")\n",
    "    elif mel_db.shape[1] > EXPECTED_WIDTH:\n",
    "        mel_db = mel_db[:, :EXPECTED_WIDTH]\n",
    "    return mel_db[np.newaxis, ..., np.newaxis]\n",
    "\n",
    "def predict_ui(audio_input):\n",
    "    if audio_input is None:\n",
    "        return \"No audio.\"\n",
    "\n",
    "    sr, y = audio_input\n",
    "    y = _mono_float32(y)\n",
    "\n",
    "    if sr != mu.SR:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=mu.SR)\n",
    "        sr = mu.SR\n",
    "\n",
    "    cap_n = int(CAPTURE_SECONDS * sr)\n",
    "    if len(y) > cap_n:\n",
    "        y = y[:cap_n]\n",
    "\n",
    "    ns = _non_silent_seconds(y, sr)\n",
    "    if ns < MIN_NON_SILENT_SECONDS:\n",
    "        return f\"Too silent ({ns:.2f}s non-silent).\"\n",
    "\n",
    "    y_proc = mu.preprocess_audio(y, sr=sr)\n",
    "    X = _make_model_input(y_proc, sr)\n",
    "\n",
    "    prob = float(model.predict(X, verbose=0)[0][0])\n",
    "    pred = int(prob > THRESHOLD)\n",
    "\n",
    "    status = \"ACCEPTED\" if pred == 1 else \"REJECTED\"\n",
    "    conf = prob if pred == 1 else (1.0 - prob)\n",
    "\n",
    "    return (\n",
    "        f\"{status}\\n\"\n",
    "        f\"P(class=1)={prob:.4f}\\n\"\n",
    "        f\"confidence={conf*100:.2f}%\\n\"\n",
    "        f\"non_silent={ns:.2f}s\\n\"\n",
    "        f\"segment_len={mu.DURATION:.1f}s\"\n",
    "    )\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(f\"# Speaker Verification\\nRecord ~{CAPTURE_SECONDS}s, Predict.\")\n",
    "    audio = gr.Audio(type=\"numpy\", sources=[\"microphone\", \"upload\"])\n",
    "    btn = gr.Button(\"Predict\")\n",
    "    out = gr.Textbox(lines=7)\n",
    "    btn.click(predict_ui, inputs=audio, outputs=out)\n",
    "\n",
    "demo.launch(show_error=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
